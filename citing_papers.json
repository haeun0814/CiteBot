{
    "Context-aware and boundary-optimized model for road marking instance segmentation using MLS point cloud intensity images": {
        "title": "Context-aware and boundary-optimized model for road marking instance segmentation using MLS point cloud intensity images",
        "authors": [
            "Dehui Li",
            "Tao Liu",
            "Ping Du",
            "Tianen Ma",
            "Shuangtong Liu"
        ],
        "arxiv_id": null,
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 1,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/a5366546e51f30f931f7c77d2ae7ab8a131f26e9",
        "isOpenAccess": false
    },
    "Siamese text classification network (SiamTCN) for multi-class multi-label information extraction of typhoon disasters from social media data": {
        "title": "Siamese text classification network (SiamTCN) for multi-class multi-label information extraction of typhoon disasters from social media data",
        "authors": [
            "Zhi He",
            "Chengle Zhou",
            "Liwei Zou",
            "Suhong Zhou",
            "Xueqiang Zhao"
        ],
        "arxiv_id": null,
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/b06de044b8be3417238d2489589ad152c6c51533",
        "isOpenAccess": false
    },
    "DFGAnet: a dual-branch multimodal fusion network based on graph and attention for emotion recognition in conversation": {
        "title": "DFGAnet: a dual-branch multimodal fusion network based on graph and attention for emotion recognition in conversation",
        "authors": [
            "Wenzhuo Liu",
            "Taoying Li",
            "Yijia Chen"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/86da5a1be53b979a934f6ffffa9d448ed4dd2d53",
        "isOpenAccess": false
    },
    "Ethical perspectives on deployment of large language model agents in biomedicine: a survey": {
        "title": "Ethical perspectives on deployment of large language model agents in biomedicine: a survey",
        "authors": [
            "Nafiseh Ghaffar Nia",
            "Amin Amiri",
            "Yuan Luo",
            "Adrienne Kline"
        ],
        "arxiv_id": null,
        "venue": "AI and Ethics",
        "year": 2025,
        "publicationTypes": [
            "Review"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/a80a058a738caebe6541e9c525db849159eefd98",
        "isOpenAccess": false
    },
    "OF-DETR: an efficient end-to-end detector for tiny traffic targets in aerial images": {
        "title": "OF-DETR: an efficient end-to-end detector for tiny traffic targets in aerial images",
        "authors": [
            "Jie Hu",
            "Hanzhang Huang",
            "Feiyu Zhao",
            "Yuxuan Tang",
            "Shuaidi He",
            "Xinghao Chen",
            "Qixiang Guo",
            "Minchao Zhang"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/4b6b1e5a2253304824ad1cafaa943ca5c923fd2b",
        "isOpenAccess": false
    },
    "Context-aware feature complementary screening network for mass segmentation in whole mammograms": {
        "title": "Context-aware feature complementary screening network for mass segmentation in whole mammograms",
        "authors": [
            "Qingkun Guo",
            "Mei Liu",
            "Luhao Sun",
            "Chao Li",
            "Wenzong Jiang",
            "Weifeng Liu",
            "Lin Cong",
            "Zhiyong Yu",
            "Baodi Liu"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/b8063e58f79e780ca7f514bb28603b0e87aa2445",
        "isOpenAccess": false
    },
    "BccT: an efficient transformer model for blood cell classification": {
        "title": "BccT: an efficient transformer model for blood cell classification",
        "authors": [
            "Hanruo Zhu",
            "Ziquan Zhu",
            "Si-Yuan Lu"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/ecefd2c0f7d8239bc4727b803066cf58c5bbe68a",
        "isOpenAccess": false
    },
    "Mamba-transformer for low-light image enhancement in HVI color space": {
        "title": "Mamba-transformer for low-light image enhancement in HVI color space",
        "authors": [
            "Zepu Xu",
            "Shijie Hao"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/1b19726ccc2c9b90746f1b4624d2b171ccbb4095",
        "isOpenAccess": false
    },
    "Angle and graph topology enhanced framework with dual-channel mixed token progressing unit for sign language production": {
        "title": "Angle and graph topology enhanced framework with dual-channel mixed token progressing unit for sign language production",
        "authors": [
            "Yarun Yang",
            "Qingshan Wang",
            "Qi Wang",
            "Sheng Chen"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/3e436a9886e47a5730297b195b48c2a1ac6cdde5",
        "isOpenAccess": false
    },
    "MAWT: a market-contextual adaptive wavelet transformer for stock forecasting": {
        "title": "MAWT: a market-contextual adaptive wavelet transformer for stock forecasting",
        "authors": [
            "Hao Guo",
            "Yuefeng Cen",
            "Gang Cen",
            "Cheng Zhao"
        ],
        "arxiv_id": null,
        "venue": "International Journal of Data Science and Analysis",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/67293b22341392376638589ef14a5d3a040ab5b3",
        "isOpenAccess": false
    },
    "MSMamba: enhancing medical image segmentation with a multi-scanning Mamba hybrid network": {
        "title": "MSMamba: enhancing medical image segmentation with a multi-scanning Mamba hybrid network",
        "authors": [
            "Ruoyun Liu",
            "Jianshu Chao",
            "Jiahua Lai",
            "Qingwei Guo",
            "Ke Sun",
            "Zeyu Zhang"
        ],
        "arxiv_id": null,
        "venue": "The Visual Computer",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/71331a85d06c24f6924b47e9c5f6e2629fddbf35",
        "isOpenAccess": false
    },
    "Contrastive adversarial learning with dual-sample guidance for transferable attacks on vision-language pre-training models": {
        "title": "Contrastive adversarial learning with dual-sample guidance for transferable attacks on vision-language pre-training models",
        "authors": [
            "Yiming Ren",
            "Yang Xu",
            "Sicong Zhang",
            "Xiaoyao Xie"
        ],
        "arxiv_id": null,
        "venue": "Multimedia Systems",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/151052d07f81e4e7b88972606d754ff7e6abb4e1",
        "isOpenAccess": false
    },
    "2512.03623": {
        "title": "The promising potential of vision language models for the generation of textual weather forecasts",
        "authors": [
            "Edward C. C. Steele",
            "Dinesh Mane",
            "Emilio Monti",
            "Luis Orus",
            "Rebecca Chantrill-Cheyette",
            "Matthew Couch",
            "Kirstine I. Dale",
            "Simon Eaton",
            "Govindarajan Rangarajan",
            "Amir Majlesi",
            "Steven Ramsdale",
            "Michael Sharpe",
            "Craig Smith",
            "Jonathan Smith",
            "Rebecca Yates",
            "Holly Ellis",
            "Charles Ewen"
        ],
        "arxiv_id": "2512.03623",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science",
            "Physics"
        ],
        "abstract": "Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.",
        "abstract_summary_gcp": "This paper explores a novel application of multimodal foundation models in meteorology, an area currently underdeveloped. Specifically, it uses a vision language model to automatically generate the text for the iconic Shipping Forecast directly from video-encoded gridded weather data. Early results indicate this approach holds promise for significantly improving production efficiency and fostering innovation within weather services and other sectors.",
        "url": "https://www.semanticscholar.org/paper/ecdf9818905b17b1bb16e5be61cc1a407eeaa6b1",
        "isOpenAccess": false
    },
    "2512.03804": {
        "title": "EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification",
        "authors": [
            "Hanhui Deng",
            "Xinglin Li",
            "Jie Luo",
            "Zhanpeng Jin",
            "Di Wu"
        ],
        "arxiv_id": "2512.03804",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.",
        "abstract_summary_gcp": "This paper introduces novel deep learning technologies for effectively managing and analyzing electrocardiogram (ECG) data, aiming to build an accurate and rapid diagnostic model to reduce the burden on medical workers. Unlike existing ECG models with high misdiagnosis rates, their approach uses end-to-end deep learning to automatically extract features.\n\nSpecifically, they first developed **EfficientECG**, an accurate and lightweight classification model based on the existing EfficientNet, designed to handle high-frequency, long-sequence ECG data across various lead types. Building on this, they propose a **cross-attention-based feature fusion model** that extends EfficientECG to analyze multi-lead ECG data and incorporate additional features like gender and age. Evaluations on representative datasets demonstrate the model's superiority over state-of-the-art methods in terms of high precision, multi-feature fusion capabilities, and lightweight design.",
        "url": "https://www.semanticscholar.org/paper/dec300ff2826daf69f0ba15a082be59a7fb42e01",
        "isOpenAccess": false
    },
    "2512.03620": {
        "title": "SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting",
        "authors": [
            "Hanxiu Zhang",
            "Yue Zheng"
        ],
        "arxiv_id": "2512.03620",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at https://github.com/HanxiuZhang/SELF_v2.",
        "abstract_summary_gcp": "This paper introduces **SELF**, a novel intrinsic weight-based fingerprinting scheme designed to protect the Intellectual Property (IP) of Large Language Models (LLMs).\n\nThe authors highlight that while existing fingerprinting techniques can detect unauthorized LLM usage, they are vulnerable to false claims and weight manipulations. SELF overcomes these limitations by operating independently of input data and inherently resisting false claims.\n\nIts robustness stems from two key innovations:\n1.  **Fingerprint Extraction:** It generates unique, scalable, and transformation-invariant fingerprints by applying singular value and eigenvalue decomposition to the LLM's attention weights.\n2.  **Fingerprint Comparison:** It uses a neural network-based method, incorporating few-shot learning and data augmentation, for effective similarity comparison between fingerprints.\n\nExperimental results demonstrate SELF's high accuracy in detecting IP infringement and its strong resilience against various downstream modifications, including quantization, pruning, and fine-tuning attacks.",
        "url": "https://www.semanticscholar.org/paper/d7563bb046a3ff2e6fab35f507476cb99e219b14",
        "isOpenAccess": false
    },
    "2512.04021": {
        "title": "C3G: Learning Compact 3D Representations with 2K Gaussians",
        "authors": [
            "Honggyu An",
            "Jaewoo Jung",
            "Mungyeom Kim",
            "Sunghwan Hong",
            "Chaehyun Kim",
            "Kazumi Fukuda",
            "Minkyeong Jeon",
            "Jisang Han",
            "Takuya Narihira",
            "Hyuna Ko",
            "Junsu Kim",
            "Yuki Mitsufuji",
            "Seungryong Kim"
        ],
        "arxiv_id": "2512.04021",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.",
        "abstract_summary_gcp": "This paper addresses the challenge of feed-forward 3D scene reconstruction and understanding from unposed, sparse views. Existing methods, which use per-pixel 3D Gaussian Splatting for reconstruction followed by 2D-to-3D feature lifting, are criticized for generating excessive and redundant Gaussians. This leads to high memory overhead, sub-optimal multi-view feature aggregation, and degraded performance in novel view synthesis and scene understanding.\n\nTo overcome these limitations, the authors propose C3G, a novel feed-forward framework that estimates a **compact set of 3D Gaussians** only at essential spatial locations, thus minimizing redundancy. C3G introduces **learnable tokens** that aggregate multi-view features via **self-attention** to guide the generation of these compact Gaussians, ensuring each integrates relevant visual information across views. The learned attention patterns are then exploited for efficient Gaussian decoding and feature lifting.\n\nExtensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate C3G's effectiveness. The results show that this compact yet geometrically meaningful representation achieves high-quality scene reconstruction and understanding with superior memory efficiency and feature fidelity compared to previous methods.",
        "url": "https://www.semanticscholar.org/paper/d50203b3804c75a8158202047ee142ae352fa181",
        "isOpenAccess": false
    },
    "2512.03471": {
        "title": "SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening",
        "authors": [
            "Ian Henriques",
            "Lynda Elhassar",
            "Sarvesh Relekar",
            "Denis Walrave",
            "Shayan Hassantabar",
            "Vishu Ghanakota",
            "Adel Laoui",
            "Mahmoud Aich",
            "Rafia Tir",
            "Mohamed Zerguine",
            "Samir Louafi",
            "Moncef Kimouche",
            "Emmanuel Cosson",
            "N. Jha"
        ],
        "arxiv_id": "2512.03471",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.",
        "abstract_summary_gcp": "This paper introduces **SweetDeep**, a compact neural network designed for scalable and cost-effective type 2 diabetes detection, addressing the limitations of current invasive and costly biochemical assays.\n\nSweetDeep was trained on physiological and demographic data collected from 285 participants (both diabetic and non-diabetic) in the EU and MENA regions, using Samsung Galaxy Watch 7 devices under real-world, \"free-living\" conditions over six days. Each participant contributed approximately 20 two-minute sensor recordings.\n\nDespite comprising fewer than 3,000 parameters, SweetDeep achieved a patient-level accuracy of **82.5%** (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) in three-fold cross-validation. Its expected calibration error was 5.5%, and allowing it to abstain on less than 10% of low-confidence predictions further boosted accuracy to 84.5%.\n\nThese findings suggest that combining engineered features with lightweight AI models can enable accurate, rapid, and generalizable detection of type 2 diabetes using consumer wearables in real-world settings.",
        "url": "https://www.semanticscholar.org/paper/e2db8d9dd30ebb5d47b10ecb813379b2126bf714",
        "isOpenAccess": false
    },
    "2512.03722": {
        "title": "Tutorial on Large Language Model-Enhanced Reinforcement Learning for Wireless Networks",
        "authors": [
            "Lingyi Cai",
            "Wenjie Fu",
            "Yuxi Huang",
            "Ruichen Zhang",
            "Yinqiu Liu",
            "Jiawen Kang",
            "Zehui Xiong",
            "Tao Jiang",
            "Dusit Niyato",
            "Xianbin Wang",
            "Shiwen Mao",
            "Xuemin Shen"
        ],
        "arxiv_id": "2512.03722",
        "venue": "",
        "year": 2025,
        "publicationTypes": [
            "Review"
        ],
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Reinforcement Learning (RL) has shown remarkable success in enabling adaptive and data-driven optimization for various applications in wireless networks. However, classical RL suffers from limitations in generalization, learning feedback, interpretability, and sample efficiency in dynamic wireless environments. Large Language Models (LLMs) have emerged as a transformative Artificial Intelligence (AI) paradigm with exceptional capabilities in knowledge generalization, contextual reasoning, and interactive generation, which have demonstrated strong potential to enhance classical RL. This paper serves as a comprehensive tutorial on LLM-enhanced RL for wireless networks. We propose a taxonomy to categorize the roles of LLMs into four critical functions: state perceiver, reward designer, decision-maker, and generator. Then, we review existing studies exploring how each role of LLMs enhances different stages of the RL pipeline. Moreover, we provide a series of case studies to illustrate how to design and apply LLM-enhanced RL in low-altitude economy networking, vehicular networks, and space-air-ground integrated networks. Finally, we conclude with a discussion on potential future directions for LLM-enhanced RL and offer insights into its future development in wireless networks.",
        "abstract_summary_gcp": "This paper presents a comprehensive tutorial on enhancing Reinforcement Learning (RL) with Large Language Models (LLMs) for wireless networks.\n\nIt begins by acknowledging RL's success in wireless optimization but highlights its limitations in generalization, learning feedback, interpretability, and sample efficiency in dynamic wireless environments. LLMs are then introduced as a transformative AI paradigm, offering exceptional capabilities in knowledge generalization, contextual reasoning, and interactive generation, which can address these classical RL shortcomings.\n\nThe core contributions include:\n1.  **A novel taxonomy** categorizing LLM roles into four critical functions: **state perceiver, reward designer, decision-maker, and generator**.\n2.  **A review** of existing studies, examining how each of these LLM roles enhances different stages of the RL pipeline.\n3.  **Practical case studies** demonstrating the design and application of LLM-enhanced RL in diverse areas like low-altitude economy networking, vehicular networks, and space-air-ground integrated networks.\n\nFinally, the paper discusses potential future directions and offers insights into the further development of LLM-enhanced RL in wireless communications.",
        "url": "https://www.semanticscholar.org/paper/1cff2a420612e5bca0caa20e47f9421e092ccc10",
        "isOpenAccess": false
    },
    "2512.03343": {
        "title": "Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning",
        "authors": [
            "Darshan Fofadiya"
        ],
        "arxiv_id": "2512.03343",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift''where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \\citep{holtzman2019curious}. While scaling model size mitigates this \\citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head''trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector''that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.",
        "abstract_summary_gcp": "Autoregressive Language Models (LLMs) trained on Next-Token Prediction often suffer from \"Topic Drift,\" where generations deviate from the initial prompt due to a focus on local associations. To combat this, the authors introduce the **Idea-Gated Transformer**, a novel architecture designed to separate semantic planning from syntactic generation.\n\nThis model employs an auxiliary \"Idea Head\" that predicts the bag-of-words distribution for a future context, generating a latent \"Concept Vector.\" This vector then actively gates the main vocabulary during generation via a differentiable mechanism, suppressing semantically irrelevant tokens and effectively pruning the search space in real-time.\n\nExperiments on WikiText-103 show that while the Idea-Gated model achieves comparable perplexity to a standard GPT-2 baseline, it demonstrates **significantly superior \"Domain Retention.\"** This indicates the gating mechanism successfully locks generation into specific semantic clusters, resisting associative drift and offering a parameter-efficient path towards more controllable language modeling.",
        "url": "https://www.semanticscholar.org/paper/63fb21ae1a6e92a9dd95ad820607d859b4aeb69d",
        "isOpenAccess": false
    },
    "2512.03370": {
        "title": "ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding",
        "authors": [
            "Lingjun Zhao",
            "Yandong Luo",
            "James Hay",
            "Lu Gan"
        ],
        "arxiv_id": "2512.03370",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "We introduce ShelfGaussian, an open-vocabulary multi-modal Gaussian-based 3D scene understanding framework supervised by off-the-shelf vision foundation models (VFMs). Gaussian-based methods have demonstrated superior performance and computational efficiency across a wide range of scene understanding tasks. However, existing methods either model objects as closed-set semantic Gaussians supervised by annotated 3D labels, neglecting their rendering ability, or learn open-set Gaussian representations via purely 2D self-supervision, leading to degraded geometry and limited to camera-only settings. To fully exploit the potential of Gaussians, we propose a Multi-Modal Gaussian Transformer that enables Gaussians to query features from diverse sensor modalities, and a Shelf-Supervised Learning Paradigm that efficiently optimizes Gaussians with VFM features jointly at 2D image and 3D scene levels. We evaluate ShelfGaussian on various perception and planning tasks. Experiments on Occ3D-nuScenes demonstrate its state-of-the-art zero-shot semantic occupancy prediction performance. ShelfGaussian is further evaluated on an unmanned ground vehicle (UGV) to assess its in the-wild performance across diverse urban scenarios. Project website: https://lunarlab-gatech.github.io/ShelfGaussian/.",
        "abstract_summary_gcp": "ShelfGaussian is a novel open-vocabulary, multi-modal 3D scene understanding framework that utilizes Gaussian representations and is supervised by off-the-shelf vision foundation models (VFMs).\n\nIt addresses the limitations of existing Gaussian-based methods, which either model closed-set semantics (requiring 3D labels and neglecting rendering) or rely on purely 2D self-supervision (resulting in degraded geometry and being limited to camera-only settings).\n\nShelfGaussian introduces two key components:\n1.  **Multi-Modal Gaussian Transformer:** Allows Gaussians to query features from various sensor modalities.\n2.  **Shelf-Supervised Learning Paradigm:** Optimizes Gaussians using VFM features across both 2D image and 3D scene levels.\n\nThe framework demonstrates state-of-the-art zero-shot semantic occupancy prediction on the Occ3D-nuScenes benchmark and proves its practical efficacy in diverse urban environments on an unmanned ground vehicle (UGV).",
        "url": "https://www.semanticscholar.org/paper/4c417b3d6990427a99ea18657ab984270523d7cd",
        "isOpenAccess": false
    },
    "2512.03521": {
        "title": "Cross-Space Synergy: A Unified Framework for Multimodal Emotion Recognition in Conversation",
        "authors": [
            "Xiaosen Lyu",
            "Jiayu Xiong",
            "Yuren Chen",
            "Wanlong Wang",
            "Xiaoqing Dai",
            "Jing Wang"
        ],
        "arxiv_id": "2512.03521",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Multimodal Emotion Recognition in Conversation (MERC) aims to predict speakers'emotions by integrating textual, acoustic, and visual cues. Existing approaches either struggle to capture complex cross-modal interactions or experience gradient conflicts and unstable training when using deeper architectures. To address these issues, we propose Cross-Space Synergy (CSS), which couples a representation component with an optimization component. Synergistic Polynomial Fusion (SPF) serves the representation role, leveraging low-rank tensor factorization to efficiently capture high-order cross-modal interactions. Pareto Gradient Modulator (PGM) serves the optimization role, steering updates along Pareto-optimal directions across competing objectives to alleviate gradient conflicts and improve stability. Experiments show that CSS outperforms existing representative methods on IEMOCAP and MELD in both accuracy and training stability, demonstrating its effectiveness in complex multimodal scenarios.",
        "abstract_summary_gcp": "This paper introduces Cross-Space Synergy (CSS) to improve Multimodal Emotion Recognition in Conversation (MERC). MERC aims to predict emotions from textual, acoustic, and visual cues, but existing methods struggle with complex cross-modal interactions, gradient conflicts, and unstable training.\n\nCSS addresses these issues by coupling two components:\n1.  **Synergistic Polynomial Fusion (SPF):** A representation component that uses low-rank tensor factorization to efficiently capture high-order cross-modal interactions.\n2.  **Pareto Gradient Modulator (PGM):** An optimization component that alleviates gradient conflicts and improves training stability by steering updates along Pareto-optimal directions.\n\nExperiments show that CSS outperforms current methods on IEMOCAP and MELD datasets, demonstrating superior accuracy and training stability in complex multimodal scenarios.",
        "url": "https://www.semanticscholar.org/paper/58ce4bca848abba25b14d6ee9fed81f6e08aaac0",
        "isOpenAccess": false
    },
    "2512.03538": {
        "title": "AdaPower: Specializing World Foundation Models for Predictive Manipulation",
        "authors": [
            "Yuhang Huang",
            "Shilong Zou",
            "Jiazhao Zhang",
            "Xinwang Liu",
            "Ruizhen Hu",
            "Kai Xu"
        ],
        "arxiv_id": "2512.03538",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \\textbf{AdaPower} (\\textbf{Ada}pt and Em\\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.",
        "abstract_summary_gcp": "World Foundation Models (WFMs) demonstrate strong visual simulation, but their application to precise robotic control is hindered by a gap between their generative realism and the precision needed for control. Existing methods, which use WFMs for synthetic data, are computationally expensive and underutilize pre-trained Visual-Language-Action (VLA) policies.\n\nThis paper introduces **AdaPower**, a lightweight adaptation framework designed to transform general-purpose WFMs into specialist world models. AdaPower features two key components:\n1.  **Temporal-Spatial Test-Time Training (TS-TTT):** Enables adaptation during inference for improved precision.\n2.  **Memory Persistence (MP):** Ensures long-horizon consistency in predictions.\n\nIntegrated within a Model Predictive Control (MPC) framework, AdaPower empowers pre-trained VLA policies, leading to over **41% improvement** in task success rates on LIBERO benchmarks. This is achieved without needing to retrain the VLA policy, all while maintaining computational efficiency and the WFM's generalist capabilities.",
        "url": "https://www.semanticscholar.org/paper/5892afff343cdb129907bb5f98f791538c7f4c2b",
        "isOpenAccess": false
    },
    "2512.03795": {
        "title": "MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving",
        "authors": [
            "Jia Hu",
            "Zhexi Lian",
            "Xuerun Yan",
            "Ruiang Bi",
            "Dou Shen",
            "Yu Ruan",
            "Haoran Wang"
        ],
        "arxiv_id": "2512.03795",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.",
        "abstract_summary_gcp": "Autonomous Driving (AD) vehicles currently lack human-like interaction in dynamic traffic, primarily due to an insufficient understanding of social interaction mechanisms.\n\nTo address this, the paper introduces **MPCFormer**, an explainable and socially-aware AD approach. MPCFormer explicitly models multi-vehicle social interaction dynamics through a novel physics-informed, discrete state-space representation that embeds physics priors for explainability. The dynamics coefficients are learned from naturalistic driving data using a Transformer-based encoder-decoder architecture. This is highlighted as the first approach to explicitly model such dynamics.\n\nThe learned social dynamics enable the generation of diverse, human-like behaviors, while its integration with an MPC framework mitigates safety risks associated with purely learning-based methods.\n\nEvaluations demonstrate MPCFormer's effectiveness:\n*   **Open-loop (prediction):** Achieves superior social interaction awareness and the lowest trajectory prediction errors (0.86 m ADE over a 5-second horizon) on the NGSIM dataset.\n*   **Closed-loop (planning):** In complex, interactive scenarios (e.g., consecutive lane changes for off-ramp exiting), MPCFormer achieves a 94.67% planning success rate, improves driving efficiency by 15.75%, and drastically reduces collision rates from 21.25% to 0.5%, outperforming leading Reinforcement Learning-based planners.",
        "url": "https://www.semanticscholar.org/paper/832a8c7f43b258668a5bb07f8cf8529bf4f35eba",
        "isOpenAccess": false
    },
    "2512.03606": {
        "title": "Observation-driven correction of numerical weather prediction for marine winds",
        "authors": [
            "Matteo Peduto",
            "Qidong Yang",
            "Jonathan Giezendanner",
            "D. Tuia",
            "Sherrie Wang"
        ],
        "arxiv_id": "2512.03606",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.",
        "abstract_summary_gcp": "This paper introduces a novel approach to marine wind forecasting, reframing it as an observation-informed correction of global numerical weather prediction (NWP) models rather than direct forecasting. Given the sparsity and heterogeneity of ocean observations, the authors propose a transformer-based deep learning architecture that learns to adjust Global Forecast System (GFS) output by assimilating the latest in-situ observations.\n\nKey features of the model include:\n*   Handling irregular and time-varying observation sets using masking and set-based attention.\n*   Conditioning predictions on recent observation-forecast pairs via cross-attention.\n*   Employing cyclical time embeddings and coordinate-aware location representations for efficient single-pass inference at any spatial coordinate.\n\nEvaluated over the Atlantic Ocean using ICOADS observations, the model significantly reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, showing a 45% improvement at 1-hour lead time and a 13% improvement at 48 hours. Improvements are most pronounced along coastlines and shipping routes, where observations are abundant. The architecture is flexible, accommodating diverse observing platforms (ships, buoys) and generating both site-specific and basin-scale gridded predictions in a single pass. This demonstrates a practical, low-latency post-processing method that effectively complements NWP by correcting systematic forecast errors.",
        "url": "https://www.semanticscholar.org/paper/22dbcf528ed63ea3d3776d50e7f6e5d1044ea831",
        "isOpenAccess": false
    },
    "2512.04007": {
        "title": "On the Temporality for Sketch Representation Learning",
        "authors": [
            "Marcelo Isaias de Moraes Junior",
            "M. A. Ponti"
        ],
        "arxiv_id": "2512.04007",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.",
        "abstract_summary_gcp": "This work investigates the importance of the temporal aspect in learning sketch representations, addressing whether sketches should be treated as sequences and which internal orders are most relevant.\n\nThe findings indicate:\n1.  Treating sketches as sequences using traditional positional encodings is a valid approach.\n2.  Absolute coordinate representations consistently perform better than relative ones.\n3.  Non-autoregressive decoders achieve superior results compared to their autoregressive counterparts.\n4.  The significance of temporality is not universal, but rather depends on both the specific order considered and the task being evaluated.",
        "url": "https://www.semanticscholar.org/paper/e90113070515a23858f15201017d0b003f1770ec",
        "isOpenAccess": false
    },
    "2512.03598": {
        "title": "Memory-Guided Point Cloud Completion for Dental Reconstruction",
        "authors": [
            "Jianan Sun",
            "Yukang Huang",
            "Dongzhihan Wang",
            "Mingyu Fan"
        ],
        "arxiv_id": "2512.03598",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Partial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder--decoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.",
        "abstract_summary_gcp": "This paper proposes a retrieval-augmented framework for the completion of partial dental point clouds, which often suffer from large missing regions. Traditional encoder-decoder models struggle with these gaps, leading to hallucinated structures.\n\nThe new framework integrates a **learnable prototype memory** into standard encoder-decoder pipelines. After an encoder generates a global descriptor for the partial input, the model retrieves the nearest manifold prototype from this memory. This prototype is then fused with the query feature using confidence-gated weighting before being passed to the decoder.\n\nThe memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes *without* requiring tooth-position labels. This provides crucial structural priors that stabilize the inference of missing regions, allowing the decoder to focus on recovering fine details. The module is plug-and-play, compatible with existing completion backbones, and uses the same training losses.\n\nExperiments on the Teeth3DS benchmark show consistent improvements in Chamfer Distance, with visualizations demonstrating sharper cusps, ridges, and interproximal transitions. The approach offers a simple yet effective way to leverage cross-sample regularities for more accurate and faithful dental point-cloud completion.",
        "url": "https://www.semanticscholar.org/paper/4c262b350b335cb9b5294db3a89cd4b01f60e8bd",
        "isOpenAccess": false
    },
    "2512.03720": {
        "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs",
        "authors": [
            "Tengyun Ma",
            "Jiaqi Yao",
            "Daojing He",
            "Shihao Peng",
            "Yu Li",
            "Shaohui Liu",
            "Zhuotao Tian"
        ],
        "arxiv_id": "2512.03720",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.",
        "abstract_summary_gcp": "This paper addresses critical vulnerabilities in Large Language Models (LLMs) related to their instruction handling, particularly under adversarial conditions, stemming from their uniform token processing.\n\nThe authors introduce a novel vulnerability called the **Tool-Completion Attack (TCA)**, which exploits function-calling mechanisms to subvert LLM behavior. To assess this threat, they developed the **Tool-Completion benchmark**, a security assessment framework. This benchmark revealed that even state-of-the-art LLMs are highly susceptible to TCA.\n\nTo counter these vulnerabilities, the paper proposes **Context-Aware Hierarchical Learning (CAHL)**. CAHL is a sophisticated mechanism that balances semantic comprehension with role-specific instruction constraints by analyzing contextual correlations between instruction segments to build a robust, context-aware instruction hierarchy.\n\nExperiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibits strong generalization capabilities in zero-shot evaluations, and maintains performance on generic tasks. Code for their work is publicly available.",
        "url": "https://www.semanticscholar.org/paper/571921e7d0d0a4927cc7fe73ed06cf9e4f8ba15a",
        "isOpenAccess": false
    },
    "2512.03915": {
        "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models",
        "authors": [
            "X. Y. Han",
            "Yuan Zhong"
        ],
        "arxiv_id": "2512.03915",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Mathematics",
            "Computer Science"
        ],
        "abstract": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.",
        "abstract_summary_gcp": "This paper presents a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure, developed by DeepSeek's Wang et al. (2024), which addresses the operational challenge of efficiently utilizing GPUs in Sparse Mixture-of-Experts (s-MoE) models by minimizing idle experts.\n\nThe authors cast ALF-LB as a one-step-per-iteration primal-dual method for an assignment problem. In a stylized deterministic setting, this framework reveals three key structural properties:\n1.  **Monotonic improvement** of a Lagrangian objective.\n2.  A **preference rule** that effectively re-routes tokens from overloaded to underloaded experts.\n3.  An **approximate-balancing guarantee**.\n\nExtending this analysis to a generalized online optimization formulation, which accounts for the stochastic and dynamic nature of AI training, the framework identifies a **strong convexity property** of the objective. This property, under specific step-size choices, leads to a **logarithmic expected regret bound**, a significant theoretical finding for the online setting.\n\nFinally, the theoretical findings are complemented by real-world experiments conducted on 1B-parameter DeepSeekMoE models. Together, these results establish a principled framework for understanding and analyzing ALF-LB in s-MoE architectures.",
        "url": "https://www.semanticscholar.org/paper/6e1d5b48dc5aa1de581f3073bed7357cc6784075",
        "isOpenAccess": false
    },
    "2512.03838": {
        "title": "Training and Evaluation of Guideline-Based Medical Reasoning in LLMs",
        "authors": [
            "Michael Staniek",
            "Artem Sokolov",
            "Stefan Riezler"
        ],
        "arxiv_id": "2512.03838",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.",
        "abstract_summary_gcp": "This paper addresses the critical need for faithful explanations in machine learning models used for early medical prediction, a factor often neglected in favor of prediction accuracy and crucial for gaining trust from medical practitioners.\n\nThe authors propose training Large Language Models (LLMs) to follow established medical consensus guidelines step-by-step in their reasoning and prediction process. They leverage the ubiquity of these guidelines to create data by instantiating verbalized medical inference rules from electronic health records. This data is then used to fine-tune LLMs to learn these consensus rules and their potential exceptions across various medical areas.\n\nA key advantage of this approach is the ability to automatically evaluate the model's inference process for \"derivation correctness\" (faithful deduction from premises) and \"value correctness\" (comparing predictions against real-world data), directly against the consensus rules.\n\nUsing the complex Sepsis-3 consensus definition as an example, their experiments show that small, fine-tuned LLMs significantly outperform much larger LLMs employing one-shot prompting with explicit definitions, as well as models trained on general medical texts. They find that fine-tuning on verbalized rule instantiations results in nearly perfect derivation correctness for rules and exceptions on unseen patient data within a specific medical area.\n\nThe paper concludes that the primary bottleneck for early prediction with this method is not out-of-distribution generalization (as rule adherence is robust), but rather the challenge of *generalization into the future* by forecasting sparsely and irregularly sampled clinical variables. They improve this by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.",
        "url": "https://www.semanticscholar.org/paper/51198c8be4b25f7bb33840faac6641a1702ff011",
        "isOpenAccess": false
    },
    "2512.03870": {
        "title": "Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers",
        "authors": [
            "Hongzhan Lin",
            "Zhiqi Bai",
            "Xinmiao Zhang",
            "Sen Yang",
            "Xiang Li",
            "Siran Yang",
            "Yunlong Xu",
            "Jiaheng Liu",
            "Yongchi Zhao",
            "Jiamang Wang",
            "Yuchi Xu",
            "Wenbo Su",
            "Bo Zheng"
        ],
        "arxiv_id": "2512.03870",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.",
        "abstract_summary_gcp": "Transformer decoders struggle with prohibitive KV cache memory requirements at long sequence lengths. While existing cross-layer sharing methods (e.g., YOCO, CLA) attempt to mitigate this, they generally underperform within-layer methods like GQA.\n\nTo address this, an investigation into key and value information flow revealed that values predominantly derive from bottom layers, whereas keys draw from both bottom and middle layers.\n\nLeveraging this insight, the authors propose **FusedKV**, a method where top-layer KV caches are a *learnable fusion* of the most informative keys and values from the bottom and middle layers. This fusion directly processes post-RoPE keys, efficiently preserving positional information without recomputing embeddings.\n\nFor enhanced efficiency, **FusedKV-Lite** is introduced as a cross-layer sharing approach, directly sourcing top-layer KV caches from bottom-layer values and middle-layer keys, which reduces I/O overhead at a slight increase in perplexity.\n\nExperiments on LLMs ranging from 332M to 4B parameters show that FusedKV methods reduce cache memory by 50% while achieving *lower* validation perplexity than standard Transformer decoders, establishing them as a memory-efficient and high-performance architectural alternative.",
        "url": "https://www.semanticscholar.org/paper/73d41f0f4db4506225fb0c7c3fe879e4fe6ff295",
        "isOpenAccess": false
    },
    "2512.03508": {
        "title": "Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation",
        "authors": [
            "Seogkyu Jeon",
            "Kibeom Hong",
            "Hyeran Byun"
        ],
        "arxiv_id": "2512.03508",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Recent domain generalized semantic segmentation (DGSS) studies have achieved notable improvements by distilling semantic knowledge from Vision-Language Models (VLMs). However, they overlook the semantic misalignment between visual and textual contexts, which arises due to the rigidity of a fixed context prompt learned on a single source domain. To this end, we present a novel domain generalization framework for semantic segmentation, namely Domain-aware Prompt-driven Masked Transformer (DPMFormer). Firstly, we introduce domain-aware prompt learning to facilitate semantic alignment between visual and textual cues. To capture various domain-specific properties with a single source dataset, we propose domain-aware contrastive learning along with the texture perturbation that diversifies the observable domains. Lastly, to establish a framework resilient against diverse environmental changes, we have proposed the domain-robust consistency learning which guides the model to minimize discrepancies of prediction from original and the augmented images. Through experiments and analyses, we demonstrate the superiority of the proposed framework, which establishes a new state-of-the-art on various DGSS benchmarks. The code is available at https://github.com/jone1222/DPMFormer.",
        "abstract_summary_gcp": "This paper introduces **DPMFormer (Domain-aware Prompt-driven Masked Transformer)**, a novel framework for Domain Generalized Semantic Segmentation (DGSS) that addresses the semantic misalignment between visual and textual contexts in VLM-based approaches.\n\nExisting methods overlook this misalignment, which stems from the rigidity of fixed context prompts learned on single source domains. DPMFormer tackles this by:\n\n1.  **Domain-aware Prompt Learning:** To achieve better semantic alignment between visual and textual cues.\n2.  **Domain-aware Contrastive Learning with Texture Perturbation:** To diversify observable domains and capture various domain-specific properties from a single source dataset.\n3.  **Domain-robust Consistency Learning:** To guide the model in minimizing prediction discrepancies between original and augmented images, enhancing resilience against diverse environmental changes.\n\nExperiments show DPMFormer's superiority, establishing a new state-of-the-art on various DGSS benchmarks. Code is available on GitHub.",
        "url": "https://www.semanticscholar.org/paper/ff4dd2315a525a2a807076ab5f46537f0a56da84",
        "isOpenAccess": false
    },
    "2512.03608": {
        "title": "KVNAND: Efficient On-Device Large Language Model Inference Using DRAM-Free In-Flash Computing",
        "authors": [
            "Lishuo Deng",
            "Shaojie Xu",
            "Jinwu Chen",
            "Changwei Yan",
            "Jiajie Wang",
            "Zhe Jiang",
            "Weiwei Shan"
        ],
        "arxiv_id": "2512.03608",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Deploying large language models (LLMs) on edge devices enables personalized agents with strong privacy and low cost. However, with tens to hundreds of billions of parameters, single-batch autoregressive inference suffers from extremely low arithmetic intensity, creating severe weight-loading and bandwidth pressures on resource-constrained platforms. Recent in-flash computing (IFC) solutions alleviate this bottleneck by co-locating weight-related linear computations in the decode phase with flash, yet still rely on DRAM for the key-value (KV) cache. As context length grows, the KV cache can exceed model weights in size, imposing prohibitive DRAM cost and capacity requirements. Attempts to offload KV cache to flash suffer from severe performance penalties. We propose KVNAND, the first DRAM-free, IFC-based architecture that stores both model weights and KV cache entirely in compute-enabled 3D NAND flash. KVNAND addresses the fundamental performance challenges of flash under intensive KV cache access by leveraging IFC for all memory-bound operations to reduce data transfer overhead, introducing head-group parallelism to boost throughput, and employing page-level KV cache mapping to align token access patterns with flash organization. In addition, we propose a design space exploration framework that evaluates discrete and compact KVNAND variants to balance weight and KV placement, automatically identifying the optimal design trade-off. These techniques mitigate latency, energy, and reliability concerns, turning flash into a practical medium for long-context KV storage. Evaluations on MHA 7B and GQA 70B LLMs show that KVNAND achieves 1.98\\(\\times\\)/1.94\\(\\times\\)/2.05\\(\\times\\) geomean speedup at 128/1K/10K-token contexts compared to DRAM-equipped IFC designs and addresses out-of-memory failures at 100K context length.",
        "abstract_summary_gcp": "This paper introduces **KVNAND**, a novel DRAM-free architecture designed to efficiently deploy large language models (LLMs) on edge devices by storing both model weights and the key-value (KV) cache entirely within compute-enabled 3D NAND flash.\n\nThe core problem is that while in-flash computing (IFC) solutions address the weight-loading bottleneck for LLMs on resource-constrained platforms, the growing KV cache still relies on expensive and capacity-limited DRAM. As context lengths increase, the KV cache can exceed model weights in size, leading to prohibitive costs or out-of-memory issues, and attempts to offload it to traditional flash storage suffer severe performance penalties.\n\nKVNAND addresses these challenges by:\n1.  **Leveraging IFC** for *all* memory-bound operations (not just weights) to minimize data transfer overhead.\n2.  **Introducing head-group parallelism** to boost throughput for KV cache access.\n3.  **Employing page-level KV cache mapping** to align token access patterns with flash organization.\n4.  Proposing a **design space exploration framework** to optimize weight and KV placement within the flash.\n\nThese techniques mitigate latency, energy, and reliability concerns associated with using flash for intensive KV cache access. Evaluations on 7B and 70B LLMs show that KVNAND achieves an average **~2x geomean speedup** over DRAM-equipped IFC designs at various context lengths (128 to 10K tokens) and critically, **eliminates out-of-memory failures** at 100K context lengths, making long-context KV storage practical in flash.",
        "url": "https://www.semanticscholar.org/paper/3677fdd7cb7d64645ab4dfb6c609e6e9d566751d",
        "isOpenAccess": false
    },
    "2512.03818": {
        "title": "Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology",
        "authors": [
            "Kylie L. Anglin",
            "Stephanie Milan",
            "Brittney Hernandez",
            "Claudia Ventura"
        ],
        "arxiv_id": "2512.03818",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.",
        "abstract_summary_gcp": "Large language models (LLMs) are effective for text classification, but their performance is highly sensitive to prompt wording, particularly for precisely defined, theory-driven concepts found in domains like psychology. This paper introduces an empirical framework to optimize LLM classification performance via prompt engineering.\n\nThe study experimentally evaluated five prompting strategies—codebook-guided empirical selection, automatic prompt engineering, persona prompting, chain-of-thought, and explanatory prompting—using both zero-shot and few-shot classification across three constructs and two models.\n\nKey findings indicate that persona, chain-of-thought, and explanatory prompting alone do not fully overcome performance loss from poorly worded prompts. Instead, the most influential prompt features are the **construct definition**, **task framing**, and, to a lesser extent, the **provided examples**. The highest alignment with expert judgments was achieved through a **few-shot prompt that combined codebook-guided empirical prompt selection with automatic prompt engineering**.\n\nThe authors recommend that researchers generate and empirically evaluate as many prompt variants as feasible (human-crafted, automatically generated, or both) on a training dataset, selecting the best performers and validating them on a holdout set. This systematic approach offers a practical method for optimizing LLM prompts when alignment with expert judgment is crucial.",
        "url": "https://www.semanticscholar.org/paper/f5cb1bbb0cb501553938f2e1beea37729f3f85e1",
        "isOpenAccess": false
    },
    "2512.03350": {
        "title": "SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation",
        "authors": [
            "Yu Yuan",
            "Tharindu Wickremasinghe",
            "Zeeshan Nadir",
            "Xijun Wang",
            "Yiheng Chi",
            "Stanley H. Chan"
        ],
        "arxiv_id": "2512.03350",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Images and videos are discrete 2D projections of the 4D world (3D space + time). Most visual understanding, prediction, and generation operate directly on 2D observations, leading to suboptimal performance. We propose SeeU, a novel approach that learns the continuous 4D dynamics and generate the unseen visual contents. The principle behind SeeU is a new 2D$\\to$4D$\\to$2D learning framework. SeeU first reconstructs the 4D world from sparse and monocular 2D frames (2D$\\to$4D). It then learns the continuous 4D dynamics on a low-rank representation and physical constraints (discrete 4D$\\to$continuous 4D). Finally, SeeU rolls the world forward in time, re-projects it back to 2D at sampled times and viewpoints, and generates unseen regions based on spatial-temporal context awareness (4D$\\to$2D). By modeling dynamics in 4D, SeeU achieves continuous and physically-consistent novel visual generation, demonstrating strong potentials in multiple tasks including unseen temporal generation, unseen spatial generation, and video editing.",
        "abstract_summary_gcp": "SeeU is a novel approach that addresses the limitations of current visual AI, which typically operates on 2D images/videos despite them being discrete projections of a 4D (3D space + time) world.\n\nThe core of SeeU is a **2D$\\to$4D$\\to$2D learning framework**:\n1.  **2D$\\to$4D (Reconstruction):** It first reconstructs a 4D representation of the world from sparse, monocular 2D input frames.\n2.  **Discrete 4D$\\to$Continuous 4D (Dynamics Learning):** It then learns the continuous 4D dynamics of this reconstructed world, leveraging low-rank representations and physical constraints.\n3.  **4D$\\to$2D (Generation):** Finally, SeeU projects the learned 4D world forward in time and re-projects it back into 2D at desired times and viewpoints, generating unseen visual content with strong spatial-temporal context awareness.\n\nBy modeling dynamics in 4D, SeeU enables continuous and physically-consistent novel visual generation, showing significant potential for tasks such as unseen temporal generation, unseen spatial generation, and video editing.",
        "url": "https://www.semanticscholar.org/paper/f69341e1d2d35ff91af555c83634e887c9250728",
        "isOpenAccess": false
    },
    "2512.03796": {
        "title": "LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling",
        "authors": [
            "Hong-Kai Zheng",
            "Piji Li"
        ],
        "arxiv_id": "2512.03796",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.",
        "abstract_summary_gcp": "Visual Autoregressive (VAR) models generate images by processing hierarchical scales and decoding multiple tokens per scale in parallel, offering high generation quality and speed. However, this parallel token sampling within a scale can introduce structural errors, leading to suboptimal images.\n\nTo mitigate this, the paper proposes Latent Scale Rejection Sampling (LSRS). LSRS enhances VAR models by progressively refining latent token maps during inference. It uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the highest-quality map to guide the generation of subsequent scales. By prioritizing refinement in early, structurally critical scales, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency.\n\nExperiments demonstrate that LSRS significantly improves VAR's generation quality with minimal overhead. For instance, on the VAR-d30 model, LSRS reduces the FID score from 1.95 to 1.78 with only a 1% increase in inference time, and further to 1.66 with a 15% increase. LSRS thus provides an efficient test-time solution for enhancing VAR-based image generation.",
        "url": "https://www.semanticscholar.org/paper/036a1cb97af3b2c953f6bcf477de8a9f5770c096",
        "isOpenAccess": false
    },
    "2512.03644": {
        "title": "FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management",
        "authors": [
            "Bohan Zhao",
            "Yuanhong Wang",
            "Chenglin Liu",
            "Jiagi Pan",
            "Guang Yang",
            "Ruitao Liu",
            "Tingrui Zhang",
            "Kai Luo",
            "Wei Xu"
        ],
        "arxiv_id": "2512.03644",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Recent developments in large language models (LLMs) have introduced new requirements for efficient and robust training. As LLM clusters scale, node failures, lengthy recoveries, and bulky checkpoints erode efficiency. Infrequent asynchronous checkpoints trigger costly rollbacks, yet higher frequencies add prohibitive overhead. To address these challenges, we propose FFTrainer, a system designed for robust LLM training. FFTrainer leverages surplus network capacity to quickly save and load states, thereby preventing rollbacks and accelerating recovery. Compared with prior checkpointing approaches, FFTrainer reduces recovery time by up to 98% and mitigates GPU utilization loss by up to 68% without hindering normal training.",
        "abstract_summary_gcp": "LLM training on large clusters faces efficiency challenges due to node failures, lengthy recoveries, and bulky checkpoints. Existing checkpointing methods are inefficient: infrequent ones cause costly rollbacks, while frequent ones create prohibitive overhead. To solve this, FFTrainer is proposed. It leverages surplus network capacity to quickly save and load training states, thereby preventing rollbacks and accelerating recovery. FFTrainer reduces recovery time by up to 98% and mitigates GPU utilization loss by up to 68% without hindering normal training operations.",
        "url": "https://www.semanticscholar.org/paper/cfae2f94c1512c76e43891910bb5578d71c77ae9",
        "isOpenAccess": false
    },
    "2512.03424": {
        "title": "DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding",
        "authors": [
            "Bin Liu",
            "Chunyang Wang",
            "Xuelian Liu"
        ],
        "arxiv_id": "2512.03424",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "State Space Models (SSMs) demonstrate significant potential for long-sequence modeling, but their reliance on input order conflicts with the irregular nature of point clouds. Existing approaches often rely on predefined serialization strategies, which cannot adjust based on diverse geometric structures. To overcome this limitation, we propose \\textbf{DM3D}, a deformable Mamba architecture for point cloud understanding. Specifically, DM3D introduces an offset-guided Gaussian sequencing mechanism that unifies local resampling and global reordering within a deformable scan. The Gaussian-based KNN Resampling (GKR) enhances structural awareness by adaptively reorganizing neighboring points, while the Gaussian-based Differentiable Reordering (GDR) enables end-to-end optimization of serialization order. Furthermore, a Tri-Path Frequency Fusion module enhances feature complementarity and reduces aliasing. Together, these components enable structure-adaptive serialization of point clouds. Extensive experiments on benchmark datasets show that DM3D achieves state-of-the-art performance in classification, few-shot learning, and part segmentation, demonstrating that adaptive serialization effectively unlocks the potential of SSMs for point cloud understanding.",
        "abstract_summary_gcp": "This paper addresses the challenge of applying State Space Models (SSMs) to point clouds. While SSMs excel at long-sequence modeling, their reliance on a fixed input order conflicts with the irregular nature of point clouds, and existing serialization methods are rigid.\n\nTo overcome this, the authors propose **DM3D**, a deformable Mamba architecture for point cloud understanding. DM3D introduces an **offset-guided Gaussian sequencing mechanism** which unifies local resampling and global reordering. Key components include:\n\n1.  **Gaussian-based KNN Resampling (GKR)**: Enhances structural awareness by adaptively reorganizing neighboring points.\n2.  **Gaussian-based Differentiable Reordering (GDR)**: Allows end-to-end optimization of the point cloud's serialization order.\n3.  **Tri-Path Frequency Fusion module**: Improves feature complementarity and reduces aliasing.\n\nTogether, these innovations enable **structure-adaptive serialization** of point clouds. Experiments on benchmark datasets show DM3D achieves state-of-the-art performance in classification, few-shot learning, and part segmentation, demonstrating that adaptive serialization effectively unlocks the potential of SSMs for point cloud understanding.",
        "url": "https://www.semanticscholar.org/paper/9714242fec0b1d7216ffee01d2c325d5b1f4e14b",
        "isOpenAccess": false
    },
    "2512.03949": {
        "title": "Performance and efficiency of a transformer-based quark/gluon jet tagger in the ATLAS experiment",
        "authors": [
            "Atlas Collaboration"
        ],
        "arxiv_id": "2512.03949",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Physics"
        ],
        "abstract": "A deep-learning approach based on the transformer architecture is developed to distinguish between jets originating from quarks and gluons. The algorithm operates on jets with transverse momentum $p_{\\text{T}}>20$ and pseudorapidity $|\\eta|<4.5$ and takes as input several properties derived from the jet constituents, using information from the ATLAS detector's tracker and calorimeter. The algorithm's performance is evaluated by analyzing dijet data events from proton-proton collisions at $\\sqrt{s} = 13$ and $13.6$ TeV during Run 2 and Run 3 of the Large Hadron Collider. Two methods are used to obtain distributions from quark- or gluon-initiated jets in data: a matrix method fully based on Monte Carlo simulation and a new approach named `jet topics'which has less dependence on the modelling of the physics process under study. The quark and gluon identification efficiencies measured in data for the 50% quark-identification-efficiency working point vary from the simulated ones for quark-initiated (gluon-initiated) jets by factors of 0.88-1.30 (0.61-1.05) with uncertainties of 10%-70% (10%-95%). The uncertainties estimated with the jet topics method are smaller than those estimated with the matrix method, with up to 20% less systematic uncertainty in some phase-space regions. The advances in jet identification reported here provide a robust tool for precision Standard Model measurements and searches for new physics at the LHC.",
        "abstract_summary_gcp": "This paper describes the development of a deep-learning algorithm, based on the transformer architecture, designed to distinguish between quark and gluon jets. The algorithm processes jet properties derived from ATLAS detector's tracker and calorimeter for jets with transverse momentum $p_T > 20$ GeV and pseudorapidity $|\\eta| < 4.5$. Its performance was assessed using dijet data from proton-proton collisions at $\\sqrt{s} = 13$ and $13.6$ TeV (LHC Run 2 and 3).\n\nTo obtain quark and gluon jet distributions from data, two methods were used: a Monte Carlo-based matrix method and a new 'jet topics' approach designed to be less dependent on simulation. At a 50% quark-identification-efficiency working point, the measured data-to-simulation ratios for quark (gluon) jet identification efficiencies were 0.88-1.30 (0.61-1.05), with uncertainties ranging from 10-70% (10-95%). Notably, the 'jet topics' method produced smaller uncertainties, reducing systematic uncertainty by up to 20% in certain phase-space regions compared to the matrix method. This new tool represents a significant advancement for precision Standard Model measurements and new physics searches at the LHC.",
        "url": "https://www.semanticscholar.org/paper/dff850f74c796eb7717892b33ebd0c854d278d09",
        "isOpenAccess": false
    },
    "2512.03442": {
        "title": "PretrainZero: Reinforcement Active Pretraining",
        "authors": [
            "Xingrun Xing",
            "Zhiyuan Fan",
            "Jie Lou",
            "Guoqi Li",
            "Jiajun Zhang",
            "Debing Zhang"
        ],
        "arxiv_id": "2512.03442",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.",
        "abstract_summary_gcp": "This paper introduces **PretrainZero**, a novel reinforcement active learning framework designed to extend Reinforcement Learning (RL) from domain-specific post-training to general pretraining, aiming for Artificial General Intelligence (AGI).\n\nTraditional RL models for general intelligence are bottlenecked by their reliance on verifiable rewards in specific domains. PretrainZero addresses this by:\n\n1.  **Active Pretraining:** Learning a unified reasoning policy that actively identifies reasonable and informative content from a general pretraining corpus (e.g., Wikipedia) and uses RL to predict this content, mimicking human active learning.\n2.  **Self-supervised Learning:** Operating without any verifiable labels, pretrained reward models, or supervised fine-tuning. It directly pretrains reasoners on general corpora using RL, thereby overcoming the \"verification data-wall\" for general reasoning.\n3.  **Verification Scaling:** Enhancing general reasoning capabilities by progressively tackling more challenging masked spans within the pretraining process.\n\nAs a result, PretrainZero significantly improved the Qwen3-4B-Base model's performance on MMLU-Pro (8.43 points), SuperGPQA (5.96 points), and math average benchmarks (10.60 points). Furthermore, the models pretrained with PretrainZero can serve as robust reasoning foundation models for downstream RLVR (Reinforcement Learning from Verbose Reasoning) tasks.",
        "url": "https://www.semanticscholar.org/paper/0509f3a645155971dca0ac5d67da614505b71f08",
        "isOpenAccess": false
    },
    "2512.04025": {
        "title": "PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation",
        "authors": [
            "Xiaolong Li",
            "Youping Gu",
            "Xi Lin",
            "Weijie Wang",
            "Bohan Zhuang"
        ],
        "arxiv_id": "2512.04025",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA",
        "abstract_summary_gcp": "Attention mechanisms, while central to foundation models, suffer from quadratic complexity, a bottleneck that current sparse attention methods attempt to address. However, these methods typically use binary masks, leading to significant information loss when aggressively pruning key-value (KV) blocks.\n\nTo overcome this, the paper introduces **Pyramid Sparse Attention (PSA)**, a versatile module for video understanding and generation. Instead of binary masking, PSA employs **multi-level pooled KV representations**, allowing for finer mask granularity. Each query block dynamically allocates lower (more detailed) pooling levels to critical KV blocks and higher (more compressed) levels to less important ones. This creates an \"informative interpolation\" between full retention and complete pruning, akin to fixed-point quantization or feature pyramid networks.\n\nThis design effectively **mitigates information loss** while maintaining **computational efficiency** under low compute budgets. PSA also features a native, hardware-friendly kernel for efficient execution. Across video understanding and generation benchmarks, PSA consistently outperforms or matches existing sparse attention baselines, offering **superior efficiency-quality trade-offs** by preserving contextual information and visual fidelity.\n\nThe code and model weights are publicly available.",
        "url": "https://www.semanticscholar.org/paper/022061dcd2c28d1f62206d1e5745b767ebf35b0b",
        "isOpenAccess": false
    },
    "2512.03377": {
        "title": "Nexus: Higher-Order Attention Mechanisms in Transformers",
        "authors": [
            "Hanting Chen",
            "Chu Zhong",
            "Kai Han",
            "Yuchuan Tian",
            "Yuchen Liang",
            "Tianyu Guo",
            "Xinghao Chen",
            "Dacheng Tao",
            "Yunhe Wang"
        ],
        "arxiv_id": "2512.03377",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \\textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \\textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.",
        "abstract_summary_gcp": "This paper introduces the **Higher-Order Attention Network (Hon)**, a novel architecture designed to overcome a key limitation of standard Transformers. While Transformers excel in many domains, their first-order self-attention mechanism suffers from a low-rank bottleneck, hindering its ability to capture intricate, multi-hop relationships within a single layer.\n\nHon addresses this by implementing a recursive framework where Query and Key representations are not static linear projections, but are dynamically refined through **nested self-attention mechanisms**. This means Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations *before* the final attention computation.\n\nCrucially, Hon maintains parameter efficiency by employing a weight-sharing strategy across recursive steps, adding only $\\mathcal{O}(1)$ additional parameters. Theoretical analysis demonstrates that Hon successfully breaks the linear bottleneck of standard attention, and empirical results show it outperforms standard Transformers on various benchmarks.",
        "url": "https://www.semanticscholar.org/paper/9b8cb6eb3258af236d8a496a9e80b776308f577f",
        "isOpenAccess": false
    },
    "2512.03767": {
        "title": "CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond",
        "authors": [
            "Bo Qian",
            "Hanlin Wu",
            "Jiacheng Chen",
            "Yunting Xu",
            "Xiaoyu Wang",
            "Haibo Zhou",
            "Yusheng Ji"
        ],
        "arxiv_id": "2512.03767",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Engineering",
            "Computer Science",
            "Mathematics"
        ],
        "abstract": "The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.",
        "abstract_summary_gcp": "The document introduces **CaFTRA (Correlation-aware Feedback-free MIMO Transmission and Resource Allocation)**, a novel framework designed for AI-native 6G and beyond, specifically for fully-decoupled radio access networks (FD-RANs). It aims to overcome the limitations of feedback-based MIMO transmission by eliminating the need for real-time uplink feedback.\n\nCaFTRA achieves this by leveraging AI to predict channel state information (CSI) solely based on user geolocation. This prediction is performed by a **Learnable Queries-driven Transformer Network** that uses multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks, significantly improving CSI prediction precision.\n\nEliminating feedback allows for expanded downlink transmission coverage. To manage resource scheduling in these extensive-coverage scenarios, CaFTRA employs a **low-complexity, many-to-one matching theory-based algorithm** for efficient multi-base station association and multi-resource block allocation, proven to converge to a stable matching rapidly.\n\nSimulation results indicate that CaFTRA achieves stable matching convergence and delivers significant gains in spectral efficiency and user fairness compared to 5G, positioning it as a promising solution for 6G standardization.",
        "url": "https://www.semanticscholar.org/paper/5c590c2ccce5fea319078febad7ae0921c01b291",
        "isOpenAccess": false
    },
    "2512.03837": {
        "title": "Heatmap Pooling Network for Action Recognition from RGB Videos",
        "authors": [
            "Mengyuan Liu",
            "Jinfu Liu",
            "Yongkang Jiang",
            "Bin He"
        ],
        "arxiv_id": "2512.03837",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Human action recognition (HAR) in videos has garnered widespread attention due to the rich information in RGB videos. Nevertheless, existing methods for extracting deep features from RGB videos face challenges such as information redundancy, susceptibility to noise and high storage costs. To address these issues and fully harness the useful information in videos, we propose a novel heatmap pooling network (HP-Net) for action recognition from videos, which extracts information-rich, robust and concise pooled features of the human body in videos through a feedback pooling module. The extracted pooled features demonstrate obvious performance advantages over the previously obtained pose data and heatmap features from videos. In addition, we design a spatial-motion co-learning module and a text refinement modulation module to integrate the extracted pooled features with other multimodal data, enabling more robust action recognition. Extensive experiments on several benchmarks namely NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome and UAV-Human consistently verify the effectiveness of our HP-Net, which outperforms the existing human action recognition methods. Our code is publicly available at: https://github.com/liujf69/HPNet-Action.",
        "abstract_summary_gcp": "This paper addresses challenges in Human Action Recognition (HAR) from RGB videos, specifically information redundancy, noise susceptibility, and high storage costs associated with existing deep feature extraction methods.\n\nTo overcome these, the authors propose a novel **Heatmap Pooling Network (HP-Net)**. The core of HP-Net is a **feedback pooling module** that extracts information-rich, robust, and concise pooled features of the human body. These new pooled features are shown to outperform traditional pose data and heatmap features.\n\nAdditionally, HP-Net integrates these features with other multimodal data through two further components: a **spatial-motion co-learning module** and a **text refinement modulation module**, leading to more robust action recognition.\n\nExtensive experiments on several benchmarks (NTU RGB+D 60/120, Toyota-Smarthome, and UAV-Human) demonstrate HP-Net's effectiveness, consistently outperforming existing HAR methods. The code is publicly available.",
        "url": "https://www.semanticscholar.org/paper/8722b0f1e2ab9ef4cdae3778ede3eece96dbcae7",
        "isOpenAccess": false
    },
    "Performance Evaluation of Whisper-Series Speech Transcription Models on Raspberry Pi": {
        "title": "Performance Evaluation of Whisper-Series Speech Transcription Models on Raspberry Pi",
        "authors": [
            "Yue Cao"
        ],
        "arxiv_id": null,
        "venue": "",
        "year": 2025,
        "publicationTypes": [
            "Book"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/840adf90a7117dde8133ade3c601ae45c0e71389",
        "isOpenAccess": false
    },
    "Seeing Patterns Differently: Topological Geometry for Anomaly Detection in Multivariate Time Series": {
        "title": "Seeing Patterns Differently: Topological Geometry for Anomaly Detection in Multivariate Time Series",
        "authors": [
            "Kanchon Gharami",
            "Humayra Tasnim",
            "M. Akbaş",
            "Shafika Showkat Moni"
        ],
        "arxiv_id": null,
        "venue": "",
        "year": 2025,
        "publicationTypes": [
            "Book"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/66ea43df9eaf26465f2e100c78d4c9f954f8262f",
        "isOpenAccess": false
    },
    "A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge": {
        "title": "A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge",
        "authors": [
            "Zihao Ding",
            "Mufeng Zhu",
            "Zhongze Tang",
            "Sheng Wei",
            "Yao Liu"
        ],
        "arxiv_id": null,
        "venue": "",
        "year": 2025,
        "publicationTypes": [
            "Book"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/ab92c9dfcd23561c9f62b1fc9c5a05e88642838a",
        "isOpenAccess": false
    },
    "2512.02968": {
        "title": "Flexible Gravitational-Wave Parameter Estimation with Transformers",
        "authors": [
            "Annalena Kofler",
            "Maximilian Dax",
            "Stephen R. Green",
            "J. Wildberger",
            "N. Gupte",
            "Jakob H. Macke",
            "J. Gair",
            "A. Buonanno",
            "Bernhard Scholkopf"
        ],
        "arxiv_id": "2512.02968",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Physics",
            "Computer Science"
        ],
        "abstract": "Gravitational-wave data analysis relies on accurate and efficient methods to extract physical information from noisy detector signals, yet the increasing rate and complexity of observations represent a growing challenge. Deep learning provides a powerful alternative to traditional inference, but existing neural models typically lack the flexibility to handle variations in data analysis settings. Such variations accommodate imperfect observations or are required for specialized tests, and could include changes in detector configurations, overall frequency ranges, or localized cuts. We introduce a flexible transformer-based architecture paired with a training strategy that enables adaptation to diverse analysis settings at inference time. Applied to parameter estimation, we demonstrate that a single flexible model -- called Dingo-T1 -- can (i) analyze 48 gravitational-wave events from the third LIGO-Virgo-KAGRA Observing Run under a wide range of analysis configurations, (ii) enable systematic studies of how detector and frequency configurations impact inferred posteriors, and (iii) perform inspiral-merger-ringdown consistency tests probing general relativity. Dingo-T1 also improves median sample efficiency on real events from a baseline of 1.4% to 4.2%. Our approach thus demonstrates flexible and scalable inference with a principled framework for handling missing or incomplete data -- key capabilities for current and next-generation observatories.",
        "abstract_summary_gcp": "This paper addresses the growing challenge of gravitational-wave (GW) data analysis, where traditional methods struggle with increasing complexity and deep learning models often lack the flexibility for varied analysis settings (e.g., detector configurations, frequency ranges, data cuts).\n\nThe authors introduce **Dingo-T1**, a novel flexible transformer-based architecture paired with a specialized training strategy. This approach allows a single model to adapt to diverse analysis settings at inference time for parameter estimation.\n\nKey achievements of Dingo-T1 include:\n1.  Analyzing 48 GW events from the third LIGO-Virgo-KAGRA Observing Run under a wide array of analysis configurations.\n2.  Enabling systematic studies on how detector and frequency settings impact inferred posterior distributions.\n3.  Performing inspiral-merger-ringdown consistency tests to probe general relativity.\n4.  Improving median sample efficiency on real events from a baseline of 1.4% to 4.2%.\n\nDingo-T1 thus demonstrates a flexible, scalable, and principled framework for GW inference, capable of handling missing or incomplete data, which is crucial for current and next-generation observatories.",
        "url": "https://www.semanticscholar.org/paper/26d0a6d000d6b0e3843ef6c8250ca7da3c14aa88",
        "isOpenAccess": false
    },
    "2512.02496": {
        "title": "Attention-guided reference point shifting for Gaussian-mixture-based partial point set registration",
        "authors": [
            "Mizuki Kikkawa",
            "Tatsuya Yatagawa",
            "Y. Ohtake",
            "Hiromasa Suzuki"
        ],
        "arxiv_id": "2512.02496",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "This study investigates the impact of the invariance of feature vectors for partial-to-partial point set registration under translation and rotation of input point sets, particularly in the realm of techniques based on deep learning and Gaussian mixture models (GMMs). We reveal both theoretical and practical problems associated with such deep-learning-based registration methods using GMMs, with a particular focus on the limitations of DeepGMR, a pioneering study in this line, to the partial-to-partial point set registration. Our primary goal is to uncover the causes behind such methods and propose a comprehensible solution for that. To address this, we introduce an attention-based reference point shifting (ARPS) layer, which robustly identifies a common reference point of two partial point sets, thereby acquiring transformation-invariant features. The ARPS layer employs a well-studied attention module to find a common reference point rather than the overlap region. Owing to this, it significantly enhances the performance of DeepGMR and its recent variant, UGMMReg. Furthermore, these extension models outperform even prior deep learning methods using attention blocks and Transformer to extract the overlap region or common reference points. We believe these findings provide deeper insights into registration methods using deep learning and GMMs.",
        "abstract_summary_gcp": "This study investigates the impact of feature vector invariance under translation and rotation in deep-learning-based partial-to-partial point set registration, particularly those using Gaussian Mixture Models (GMMs). It uncovers theoretical and practical limitations in existing methods, focusing on DeepGMR's performance for partial-to-partial tasks.\n\nTo address these issues and acquire transformation-invariant features, the researchers propose an **attention-based reference point shifting (ARPS) layer**. This ARPS layer robustly identifies a common reference point between two partial point sets using an attention module (rather than an overlap region).\n\nThe integration of the ARPS layer significantly enhances the performance of DeepGMR and its variant, UGMMReg. Furthermore, these extended models outperform prior deep learning methods that use attention blocks or Transformers to extract overlap regions or common reference points, providing deeper insights into deep learning and GMM-based registration techniques.",
        "url": "https://www.semanticscholar.org/paper/49a0acb6cff59f7e88f1a459b873737455216617",
        "isOpenAccess": false
    },
    "2512.02556": {
        "title": "DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models",
        "authors": [
            "DeepSeek-AI",
            "Aixin Liu",
            "Aoxue Mei",
            "Bangcai Lin",
            "Bing Xue",
            "Bingxuan Wang",
            "Bingzheng Xu",
            "Bochao Wu",
            "Bowei Zhang",
            "Chaofan Lin",
            "Chen Dong",
            "Chengda Lu",
            "Chenggang Zhao",
            "Chengqi Deng",
            "Chenhao Xu",
            "C. Ruan",
            "Damai Dai",
            "Daya Guo",
            "Dejian Yang",
            "Deli Chen",
            "Erhang Li",
            "Fangqi Zhou",
            "Fangyun Lin",
            "Fucong Dai",
            "Guangbo Hao",
            "Guanting Chen",
            "Guowei Li",
            "H. Zhang",
            "Hanwei Xu",
            "Hao Li",
            "Haofen Liang",
            "Haoran Wei",
            "Haowei Zhang",
            "Haowen Luo",
            "Haozhe Ji",
            "Honghui Ding",
            "Hongxuan Tang",
            "Huanqi Cao",
            "Huazuo Gao",
            "Huixian Qu",
            "Hui Zeng",
            "Jialiang Huang",
            "Jiashi Li",
            "Jiaxin Xu",
            "Jiewen Hu",
            "JingChang Chen",
            "Jingting Xiang",
            "Jingyang Yuan",
            "Jingyuan Cheng",
            "Jinhua Zhu",
            "Jun Ran",
            "Junguang Jiang",
            "Junjie Qiu",
            "Junlong Li",
            "Junxiao Song",
            "Kai Dong",
            "Kaige Gao",
            "Kang Guan",
            "Kexin Huang",
            "Kexing Zhou",
            "Kezhao Huang",
            "K. Yu",
            "Lean Wang",
            "Lecong Zhang",
            "Lei Wang",
            "Liang Zhao",
            "Liangsheng Yin",
            "Lihua Guo",
            "Lingxiao Luo",
            "Linwang Ma",
            "Litong Wang",
            "Liyue Zhang",
            "M. S. Di",
            "M. Y. Xu",
            "Mingchuan Zhang",
            "Minghua Zhang",
            "Minghui Tang",
            "Mingxu Zhou",
            "Panpan Huang",
            "Peixin Cong",
            "Peiyi Wang",
            "Qiancheng Wang",
            "Qihao Zhu",
            "Qingyang Li",
            "Qinyu Chen",
            "Qiushi Du",
            "Ruiling Xu",
            "Ruiqi Ge",
            "Ruisong Zhang",
            "Ruizhe Pan",
            "Runji Wang",
            "Runqiu Yin",
            "Runxin Xu",
            "Ruomeng Shen",
            "Ruoyu Zhang",
            "S. H. Liu",
            "Shanghao Lu",
            "Shangyan Zhou",
            "Shanhuang Chen",
            "Shaofei Cai",
            "Shaoyuan Chen",
            "Shengding Hu",
            "Shengyu Liu",
            "Shiqiang Hu",
            "Shirong Ma",
            "Shiyu Wang",
            "Shuiping Yu",
            "Shunfeng Zhou",
            "Shuting Pan",
            "Songyang Zhou",
            "Tao Ni",
            "Tao Yun",
            "Tian Pei",
            "Tian Ye",
            "Tianyuan Yue",
            "Wangding Zeng",
            "Wen Liu",
            "Wenfeng Liang",
            "Wenjie Pang",
            "Wenjing Luo",
            "Wenjun Gao",
            "Wentao Zhang",
            "Xi Gao",
            "Xiangwen Wang",
            "Xiaoling Bi",
            "Xiaodong Liu",
            "Xiaohan Wang",
            "Xiaokang Chen",
            "Xiaokang Zhang",
            "X. Nie",
            "Xin Cheng",
            "Xin Liu",
            "Xin Xie",
            "Xingchao Liu",
            "Xingkai Yu",
            "Xingyou Li",
            "Xinyu Yang",
            "Xinyuan Li",
            "Xu Chen",
            "Xuecheng Su",
            "Xuehai Pan",
            "Xuheng Lin",
            "Xuwei Fu",
            "Y. Q. Wang",
            "Yang Zhang",
            "Yanhong Xu",
            "Yanru Ma",
            "Yao Li",
            "Yao Zhao",
            "Yaofeng Sun",
            "Yaohui Wang",
            "Yi Qian",
            "Yi Yu",
            "Yichao Zhang",
            "Yifan Ding",
            "Yifan Shi",
            "Yiliang Xiong",
            "Ying He",
            "Ying Zhou",
            "Yinmin Zhong",
            "Yishi Piao",
            "Yisong Wang",
            "Yixiao Chen",
            "Yixuan Tan",
            "Yixuan Wei",
            "Yiyang Ma",
            "Yiyuan Liu",
            "Yonglun Yang",
            "Yongqiang Guo",
            "Yongtong Wu",
            "Yu Wu",
            "Yuan Cheng",
            "Y. Ou",
            "Yuanfan Xu",
            "Yuduan Wang",
            "Yue Gong",
            "Yuhan Wu",
            "Yuheng Zou",
            "Yukun Li",
            "Yunfan Xiong",
            "Yuxiang Luo",
            "Yu-mei You",
            "Yuxuan Liu",
            "Yuyang Zhou",
            "Z. F. Wu",
            "Z. Z. Ren",
            "Zehua Zhao",
            "Zehui Ren",
            "Zhangli Sha",
            "Zhe Fu",
            "Zhean Xu",
            "Zhenda Xie",
            "Zhen-guo Zhang",
            "Zhewen Hao",
            "Zhibin Gou",
            "Zhicheng Ma",
            "Zhigang Yan",
            "Zhihong Shao",
            "Zhixian Huang",
            "Zhiyu Wu",
            "Zhuoshu Li",
            "Zhuping Zhang",
            "Zian Xu",
            "Zihao Wang",
            "Zihui Gu",
            "Zijia Zhu",
            "Zilin Li",
            "Zipeng Zhang",
            "Ziwei Xie",
            "Ziyi Gao",
            "Zizheng Pan",
            "Zongqing Yao",
            "Bei Feng",
            "Hui Li",
            "J. L. Cai",
            "Jiaqi Ni",
            "Lei Xu",
            "Meng Li",
            "Ning Tian",
            "R. J. Chen",
            "R. Jin",
            "S. S. Li",
            "Shuang Zhou",
            "Tianyu Sun",
            "X. Q. Li",
            "Xiangyue Jin",
            "Xiaojin Shen",
            "Xiaosha Chen",
            "Xinnan Song",
            "Xinyi Zhou",
            "Y. X. Zhu",
            "Yanping Huang",
            "Yaohui Li",
            "Yi Zheng",
            "Yuchen Zhu",
            "Yunxiang Ma",
            "Zhen Huang",
            "Zhipeng Xu",
            "Zhongyu Zhang",
            "Dong-Li Ji",
            "Jian Liang",
            "Jianzhong Guo",
            "Jin Chen",
            "Leyi Xia",
            "Miaojun Wang",
            "Mingming Li",
            "Peng Zhang",
            "Ruyi Chen",
            "Shangmian Sun",
            "Shaoqing Wu",
            "Shengfeng Ye",
            "T.Wang",
            "W. L. Xiao",
            "Wei An",
            "Xianzu Wang",
            "Xiaowen Sun",
            "Xiaoxiang Wang",
            "Ying Tang",
            "Y. Zha",
            "Zekai Zhang",
            "Zhenghua Ju",
            "Zhen Zhang",
            "Zihua Qu"
        ],
        "arxiv_id": "2512.02556",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "We introduce DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance. The key technical breakthroughs of DeepSeek-V3.2 are as follows: (1) DeepSeek Sparse Attention (DSA): We introduce DSA, an efficient attention mechanism that substantially reduces computational complexity while preserving model performance in long-context scenarios. (2) Scalable Reinforcement Learning Framework: By implementing a robust reinforcement learning protocol and scaling post-training compute, DeepSeek-V3.2 performs comparably to GPT-5. Notably, our high-compute variant, DeepSeek-V3.2-Speciale, surpasses GPT-5 and exhibits reasoning proficiency on par with Gemini-3.0-Pro, achieving gold-medal performance in both the 2025 International Mathematical Olympiad (IMO) and the International Olympiad in Informatics (IOI). (3) Large-Scale Agentic Task Synthesis Pipeline: To integrate reasoning into tool-use scenarios, we developed a novel synthesis pipeline that systematically generates training data at scale. This methodology facilitates scalable agentic post-training, yielding substantial improvements in generalization and instruction-following robustness within complex, interactive environments.",
        "abstract_summary_gcp": "DeepSeek-V3.2 is a new model that prioritizes high computational efficiency alongside superior reasoning and agent performance. Its core innovations include:\n\n1.  **DeepSeek Sparse Attention (DSA):** An efficient attention mechanism that significantly reduces computational complexity while maintaining performance in long-context scenarios.\n2.  **Scalable Reinforcement Learning Framework:** Through a robust RL protocol and scaled post-training, DeepSeek-V3.2 performs comparably to GPT-5. A high-compute variant, DeepSeek-V3.2-Speciale, reportedly surpasses GPT-5 and matches Gemini-3.0-Pro's reasoning, achieving gold medals in the 2025 IMO and IOI.\n3.  **Large-Scale Agentic Task Synthesis Pipeline:** A novel pipeline that systematically generates training data at scale to integrate reasoning into tool-use scenarios, enhancing generalization and instruction-following robustness in complex environments.",
        "url": "https://www.semanticscholar.org/paper/1dc2281d4df5bd34f66aeb10e5b4741a27e23a9a",
        "isOpenAccess": false
    },
    "Zero-shot realistic image deblurring with consistency model": {
        "title": "Zero-shot realistic image deblurring with consistency model",
        "authors": [
            "Zhaohan Wang",
            "Chengjun Chen",
            "Chenggang Dai"
        ],
        "arxiv_id": null,
        "venue": "Complex & Intelligent Systems",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/175b605fc33a0ec790d1935565d2a8e6c15eba91",
        "isOpenAccess": false
    },
    "Integrating histopathology and genomic data: a comparative study of fusion methods for breast cancer survival prediction": {
        "title": "Integrating histopathology and genomic data: a comparative study of fusion methods for breast cancer survival prediction",
        "authors": [
            "Younes Akbari",
            "F. Abdullakutty",
            "Somaya Al Maadeed",
            "Ahmed Bouridane",
            "Rifat Hamoudi"
        ],
        "arxiv_id": null,
        "venue": "Complex & Intelligent Systems",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/718792e5ac433904796456aa410bac94f3f45283",
        "isOpenAccess": false
    },
    "Docsentinet: a adaptive architecture for efficient document-level sentiment analysis": {
        "title": "Docsentinet: a adaptive architecture for efficient document-level sentiment analysis",
        "authors": [
            "Xiaoyang Wang",
            "Wenfeng Liu",
            "Yuzhen Yang",
            "Yaling Gao",
            "Qiaoqiao Du",
            "Longqing Bao"
        ],
        "arxiv_id": null,
        "venue": "International Journal of Data Science and Analysis",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/477ff61f4884b5e57f715aac25d0b2dd9403aef4",
        "isOpenAccess": false
    },
    "2512.02535": {
        "title": "AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning",
        "authors": [
            "Jeric Lew",
            "Yuhong Cao",
            "Derek Ming Siang Tan",
            "G. Sartoretti"
        ],
        "arxiv_id": "2512.02535",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Information gathering in large-scale or time-critical scenarios (e.g., environmental monitoring, search and rescue) requires broad coverage within limited time budgets, motivating the use of multi-agent systems. These scenarios are commonly formulated as multi-agent informative path planning (MAIPP), where multiple agents must coordinate to maximize information gain while operating under budget constraints. A central challenge in MAIPP is ensuring effective coordination while the belief over the environment evolves with incoming measurements. Recent learning-based approaches address this by using distributions over future positions as\"intent\"to support coordination. However, these autoregressive intent predictors are computationally expensive and prone to compounding errors. Inspired by the effectiveness of diffusion models as expressive, long-horizon policies, we propose AID, a fully decentralized MAIPP framework that leverages diffusion models to generate long-term trajectories in a non-autoregressive manner. AID first performs behavior cloning on trajectories produced by existing MAIPP planners and then fine-tunes the policy using reinforcement learning via Diffusion Policy Policy Optimization (DPPO). This two-stage pipeline enables the policy to inherit expert behavior while learning improved coordination through online reward feedback. Experiments demonstrate that AID consistently improves upon the MAIPP planners it is trained from, achieving up to 4x faster execution and 17% increased information gain, while scaling effectively to larger numbers of agents. Our implementation is publicly available at https://github.com/marmotlab/AID.",
        "abstract_summary_gcp": "This paper introduces **AID**, a fully decentralized multi-agent informative path planning (MAIPP) framework designed for large-scale or time-critical information gathering scenarios (e.g., environmental monitoring, search and rescue).\n\nMAIPP traditionally involves coordinating multiple agents to maximize information gain within budget constraints, but a central challenge is maintaining effective coordination as the environment's belief state evolves. Existing learning-based approaches often rely on computationally expensive and error-prone autoregressive \"intent\" predictors for coordination.\n\nAID addresses this by leveraging **diffusion models** to generate long-term trajectories in a **non-autoregressive** manner. Its training pipeline involves two stages:\n1.  **Behavior Cloning:** Initial learning from trajectories produced by existing MAIPP planners.\n2.  **Reinforcement Learning Fine-tuning:** Optimization using Diffusion Policy Policy Optimization (DPPO) to improve coordination through online reward feedback.\n\nExperiments demonstrate that AID consistently improves upon the MAIPP planners it is trained from, achieving significant benefits: up to **4x faster execution**, up to **17% increased information gain**, and effective scaling to a larger number of agents.",
        "url": "https://www.semanticscholar.org/paper/9ea5ef130fb10e3b6794b06838da529710b00efc",
        "isOpenAccess": false
    },
    "2512.02447": {
        "title": "Temporal Dynamics Enhancer for Directly Trained Spiking Object Detectors",
        "authors": [
            "Fan Luo",
            "Zeyu Gao",
            "Xinhao Luo",
            "Kai Zhao",
            "Yanfeng Lu"
        ],
        "arxiv_id": "2512.02447",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Spiking Neural Networks (SNNs), with their brain-inspired spatiotemporal dynamics and spike-driven computation, have emerged as promising energy-efficient alternatives to Artificial Neural Networks (ANNs). However, existing SNNs typically replicate inputs directly or aggregate them into frames at fixed intervals. Such strategies lead to neurons receiving nearly identical stimuli across time steps, severely limiting the model's expressive power, particularly in complex tasks like object detection. In this work, we propose the Temporal Dynamics Enhancer (TDE) to strengthen SNNs'capacity for temporal information modeling. TDE consists of two modules: a Spiking Encoder (SE) that generates diverse input stimuli across time steps, and an Attention Gating Module (AGM) that guides the SE generation based on inter-temporal dependencies. Moreover, to eliminate the high-energy multiplication operations introduced by the AGM, we propose a Spike-Driven Attention (SDA) to reduce attention-related energy consumption. Extensive experiments demonstrate that TDE can be seamlessly integrated into existing SNN-based detectors and consistently outperforms state-of-the-art methods, achieving mAP50-95 scores of 57.7% on the static PASCAL VOC dataset and 47.6% on the neuromorphic EvDET200K dataset. In terms of energy consumption, the SDA consumes only 0.240 times the energy of conventional attention modules.",
        "abstract_summary_gcp": "This paper introduces the **Temporal Dynamics Enhancer (TDE)** to overcome a limitation in existing Spiking Neural Networks (SNNs): their inability to effectively model temporal information due to redundant input stimuli across time steps. Current SNNs often replicate inputs directly or aggregate them into fixed frames, which severely restricts their expressive power, especially for complex tasks like object detection.\n\nTDE addresses this by:\n1.  **Spiking Encoder (SE):** Generates diverse input stimuli at each time step, preventing neurons from receiving nearly identical signals repeatedly.\n2.  **Attention Gating Module (AGM):** Guides the SE's generation process by leveraging inter-temporal dependencies, ensuring relevant and dynamic input.\n\nTo mitigate the high-energy cost of AGM's multiplication operations, the authors also propose **Spike-Driven Attention (SDA)**, significantly reducing attention-related energy consumption.\n\nExtensive experiments demonstrate that TDE can be seamlessly integrated into existing SNN-based detectors, consistently outperforming state-of-the-art methods. It achieves mAP50-95 scores of 57.7% on the PASCAL VOC dataset and 47.6% on the neuromorphic EvDET200K dataset. Furthermore, the SDA module proves highly energy-efficient, consuming only 0.240 times the energy of conventional attention modules.",
        "url": "https://www.semanticscholar.org/paper/23592edadb4751d29ae948626c7f2e6243ed505e",
        "isOpenAccess": false
    },
    "2512.02619": {
        "title": "Quantum LLMs Using Quantum Computing to Analyze and Process Semantic Information",
        "authors": [
            "Timo Aukusti Laine"
        ],
        "arxiv_id": "2512.02619",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Physics"
        ],
        "abstract": "We present a quantum computing approach to analyzing Large Language Model (LLM) embeddings, leveraging complex-valued representations and modeling semantic relationships using quantum mechanical principles. By establishing a direct mapping between LLM semantic spaces and quantum circuits, we demonstrate the feasibility of estimating semantic similarity using quantum hardware. One of the key results is the experimental calculation of cosine similarity between Google Sentence Transformer embeddings using a real quantum computer, providing a tangible demonstration of a quantum approach to semantic analysis. This work reveals a connection between LLMs and quantum mechanics, suggesting that these principles can offer new perspectives on semantic representation and processing, and paving the way for future development of quantum algorithms for natural language processing.",
        "abstract_summary_gcp": "This work presents a quantum computing approach for analyzing Large Language Model (LLM) embeddings. It maps LLM semantic spaces to quantum circuits, using complex-valued representations and quantum mechanical principles to model semantic relationships. A key achievement is the experimental calculation of cosine similarity between Google Sentence Transformer embeddings on a *real quantum computer*, demonstrating the feasibility of using quantum hardware for semantic analysis. This research highlights a novel connection between LLMs and quantum mechanics, suggesting new avenues for understanding semantic representation and paving the way for future quantum algorithms in natural language processing.",
        "url": "https://www.semanticscholar.org/paper/6f8dec804dfe6a205219a5a27111bb572b11a4b2",
        "isOpenAccess": false
    },
    "2512.02713": {
        "title": "Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs",
        "authors": [
            "Theodoros Aivalis",
            "I. Klampanos",
            "Antonis Troumpoukis",
            "J. Jose"
        ],
        "arxiv_id": "2512.02713",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.",
        "abstract_summary_gcp": "This paper introduces a framework to address concerns around transparency, accountability, and copyright in powerful generative models, specifically by explaining how training data influences model output. The core of the method involves interpreting generative outputs through the automatic construction of **ontology-aligned knowledge graphs (KGs)**.\n\nRecognizing the difficulty of extracting structured, ontology-consistent information from complex visual content, the framework leverages **multimodal large language models (LLMs)**. These LLMs are used to extract structured triples (subject-predicate-object relationships) directly from images, ensuring alignment with a predefined domain-specific ontology.\n\nBy comparing the KGs of generated images with those of their training counterparts, the system can trace potential influences from the training data. This capability provides benefits such as improved copyright analysis, enhanced dataset transparency, and more interpretable AI. The method's effectiveness is validated through experiments on both locally trained models (via unlearning) and large-scale models (through a style-specific analysis). Ultimately, this framework aims to foster human collaboration, creativity, and curiosity in AI development.",
        "url": "https://www.semanticscholar.org/paper/a5c9fe3dadf8a0deafb5bb96288c5a3480612ca5",
        "isOpenAccess": false
    },
    "2512.02321": {
        "title": "LeechHijack: Covert Computational Resource Exploitation in Intelligent Agent Systems",
        "authors": [
            "Yuanhe Zhang",
            "Weiliu Wang",
            "Zhenhong Zhou",
            "Kun Wang",
            "Jie Zhang",
            "Li Sun",
            "Yang Liu",
            "Sen Su"
        ],
        "arxiv_id": "2512.02321",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in reasoning, planning, and tool usage. The recently proposed Model Context Protocol (MCP) has emerged as a unifying framework for integrating external tools into agent systems, enabling a thriving open ecosystem of community-built functionalities. However, the openness and composability that make MCP appealing also introduce a critical yet overlooked security assumption -- implicit trust in third-party tool providers. In this work, we identify and formalize a new class of attacks that exploit this trust boundary without violating explicit permissions. We term this new attack vector implicit toxicity, where malicious behaviors occur entirely within the allowed privilege scope. We propose LeechHijack, a Latent Embedded Exploit for Computation Hijacking, in which an adversarial MCP tool covertly expropriates the agent's computational resources for unauthorized workloads. LeechHijack operates through a two-stage mechanism: an implantation stage that embeds a benign-looking backdoor in a tool, and an exploitation stage where the backdoor activates upon predefined triggers to establish a command-and-control channel. Through this channel, the attacker injects additional tasks that the agent executes as if they were part of its normal workflow, effectively parasitizing the user's compute budget. We implement LeechHijack across four major LLM families. Experiments show that LeechHijack achieves an average success rate of 77.25%, with a resource overhead of 18.62% compared to the baseline. This study highlights the urgent need for computational provenance and resource attestation mechanisms to safeguard the emerging MCP ecosystem.",
        "abstract_summary_gcp": "This paper identifies a critical security vulnerability in LLM-based agents utilizing the Model Context Protocol (MCP) – the implicit trust placed in third-party tools. It introduces a new class of attacks called \"implicit toxicity,\" where malicious actions occur within the agent's legitimate privilege scope.\n\nThe authors propose **LeechHijack**, a Latent Embedded Exploit for Computation Hijacking. This attack involves two stages:\n1.  **Implantation:** A benign-appearing backdoor is embedded within an MCP tool.\n2.  **Exploitation:** Upon activation by specific triggers, the backdoor establishes a command-and-control channel. Through this channel, an attacker injects additional, unauthorized tasks that the agent executes, effectively usurping the user's computational resources.\n\nExperiments across four LLM families show that LeechHijack achieves a 77.25% success rate, incurring an average resource overhead of 18.62%. The study concludes by emphasizing the urgent need for computational provenance and resource attestation to secure the MCP ecosystem.",
        "url": "https://www.semanticscholar.org/paper/c7463808b05cc4dd058a5b5073c823dd2a69ab8a",
        "isOpenAccess": false
    },
    "2512.02764": {
        "title": "PEFT-Factory: Unified Parameter-Efficient Fine-Tuning of Autoregressive Large Language Models",
        "authors": [
            "Róbert Belanec",
            "Ivan Srba",
            "M. Bieliková"
        ],
        "arxiv_id": "2512.02764",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods address the increasing size of Large Language Models (LLMs). Currently, many newly introduced PEFT methods are challenging to replicate, deploy, or compare with one another. To address this, we introduce PEFT-Factory, a unified framework for efficient fine-tuning LLMs using both off-the-shelf and custom PEFT methods. While its modular design supports extensibility, it natively provides a representative set of 19 PEFT methods, 27 classification and text generation datasets addressing 12 tasks, and both standard and PEFT-specific evaluation metrics. As a result, PEFT-Factory provides a ready-to-use, controlled, and stable environment, improving replicability and benchmarking of PEFT methods. PEFT-Factory is a downstream framework that originates from the popular LLaMA-Factory, and is publicly available at https://github.com/kinit-sk/PEFT-Factory",
        "abstract_summary_gcp": "PEFT-Factory is a unified, modular framework designed to address the challenges of replicating, deploying, and comparing Parameter-Efficient Fine-Tuning (PEFT) methods for Large Language Models (LLMs). It provides a ready-to-use, controlled environment that supports both off-the-shelf and custom PEFT techniques. The framework natively includes 19 PEFT methods, 27 datasets for 12 classification and text generation tasks, and a range of standard and PEFT-specific evaluation metrics, thereby improving the replicability and benchmarking of PEFT methods. PEFT-Factory is a downstream project of LLaMA-Factory and is publicly available on GitHub.",
        "url": "https://www.semanticscholar.org/paper/6cb4771076b56673ad54a966635bf585ec641923",
        "isOpenAccess": false
    },
    "2512.02727": {
        "title": "DF-Mamba: Deformable State Space Modeling for 3D Hand Pose Estimation in Interactions",
        "authors": [
            "Yifan Zhou",
            "Takehiko Ohkawa",
            "Guwenxiao Zhou",
            "Kanoko Goto",
            "Takumi Hirose",
            "Yusuke Sekikawa",
            "Nakamasa Inoue"
        ],
        "arxiv_id": "2512.02727",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Modeling daily hand interactions often struggles with severe occlusions, such as when two hands overlap, which highlights the need for robust feature learning in 3D hand pose estimation (HPE). To handle such occluded hand images, it is vital to effectively learn the relationship between local image features (e.g., for occluded joints) and global context (e.g., cues from inter-joints, inter-hands, or the scene). However, most current 3D HPE methods still rely on ResNet for feature extraction, and such CNN's inductive bias may not be optimal for 3D HPE due to its limited capability to model the global context. To address this limitation, we propose an effective and efficient framework for visual feature extraction in 3D HPE using recent state space modeling (i.e., Mamba), dubbed Deformable Mamba (DF-Mamba). DF-Mamba is designed to capture global context cues beyond standard convolution through Mamba's selective state modeling and the proposed deformable state scanning. Specifically, for local features after convolution, our deformable scanning aggregates these features within an image while selectively preserving useful cues that represent the global context. This approach significantly improves the accuracy of structured 3D HPE, with comparable inference speed to ResNet-50. Our experiments involve extensive evaluations on five divergent datasets including single-hand and two-hand scenarios, hand-only and hand-object interactions, as well as RGB and depth-based estimation. DF-Mamba outperforms the latest image backbones, including VMamba and Spatial-Mamba, on all datasets and achieves state-of-the-art performance.",
        "abstract_summary_gcp": "This paper introduces **Deformable Mamba (DF-Mamba)**, a novel and efficient framework for visual feature extraction in 3D Hand Pose Estimation (HPE), specifically designed to overcome challenges posed by severe hand occlusions.\n\nThe core problem is that existing 3D HPE methods, often based on ResNet, struggle with global context modeling, which is crucial for understanding occluded hands by relating local features to broader inter-joint, inter-hand, or scene cues.\n\nDF-Mamba addresses this by leveraging recent state space modeling (Mamba) and a proposed **deformable state scanning** mechanism. This allows it to capture global context beyond standard convolutions by selectively aggregating local features and preserving useful global cues.\n\nThe framework significantly improves 3D HPE accuracy, achieving state-of-the-art performance. It was extensively evaluated on five diverse datasets, including single-hand, two-hand, hand-object, RGB, and depth-based scenarios, outperforming other advanced Mamba-based backbones (VMamba, Spatial-Mamba). Importantly, DF-Mamba maintains an inference speed comparable to ResNet-50.",
        "url": "https://www.semanticscholar.org/paper/4a4617355a258f0c6e3ae9fe94cec3ce8faeb927",
        "isOpenAccess": false
    },
    "2512.02633": {
        "title": "Zero-Shot Instruction Following in RL via Structured LTL Representations",
        "authors": [
            "Mattia Giuri",
            "Mathias Jackermeier",
            "Alessandro Abate"
        ],
        "arxiv_id": "2512.02633",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Linear temporal logic (LTL) is a compelling framework for specifying complex, structured tasks for reinforcement learning (RL) agents. Recent work has shown that interpreting LTL instructions as finite automata, which can be seen as high-level programs monitoring task progress, enables learning a single generalist policy capable of executing arbitrary instructions at test time. However, existing approaches fall short in environments where multiple high-level events (i.e., atomic propositions) can be true at the same time and potentially interact in complicated ways. In this work, we propose a novel approach to learning a multi-task policy for following arbitrary LTL instructions that addresses this shortcoming. Our method conditions the policy on sequences of simple Boolean formulae, which directly align with transitions in the automaton, and are encoded via a graph neural network (GNN) to yield structured task representations. Experiments in a complex chess-based environment demonstrate the advantages of our approach.",
        "abstract_summary_gcp": "This paper addresses a limitation in current Reinforcement Learning (RL) approaches that use Linear Temporal Logic (LTL) to specify complex tasks. While LTL, interpreted as finite automata, enables learning a single generalist policy for arbitrary instructions, existing methods falter in environments where multiple high-level events (atomic propositions) are simultaneously true and interact.\n\nThe authors propose a novel method that conditions the RL policy on **sequences of simple Boolean formulae**, which directly correspond to transitions in the LTL automaton. These Boolean formulae are then encoded using a **Graph Neural Network (GNN)** to create structured task representations. This approach allows for learning a multi-task policy that can handle the complexities of concurrent and interacting events, demonstrating its effectiveness in a challenging chess-based environment.",
        "url": "https://www.semanticscholar.org/paper/06542ce9cd5309c7117dfa0b421764ce15069bdb",
        "isOpenAccess": false
    },
    "2512.03018": {
        "title": "AutoBrep: Autoregressive B-Rep Generation with Unified Topology and Geometry",
        "authors": [
            "Xiang Xu",
            "P. Jayaraman",
            "J. Lambourne",
            "Yilin Liu",
            "Durvesh Malpure",
            "Pete Meltzer"
        ],
        "arxiv_id": "2512.03018",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "The boundary representation (B-Rep) is the standard data structure used in Computer-Aided Design (CAD) for defining solid models. Despite recent progress, directly generating B-Reps end-to-end with precise geometry and watertight topology remains a challenge. This paper presents AutoBrep, a novel Transformer model that autoregressively generates B-Reps with high quality and validity. AutoBrep employs a unified tokenization scheme that encodes both geometric and topological characteristics of a B-Rep model as a sequence of discrete tokens. Geometric primitives (i.e., surfaces and curves) are encoded as latent geometry tokens, and their structural relationships are defined as special topological reference tokens. Sequence order in AutoBrep naturally follows a breadth first traversal of the B-Rep face adjacency graph. At inference time, neighboring faces and edges along with their topological structure are progressively generated. Extensive experiments demonstrate the advantages of our unified representation when coupled with next-token prediction for B-Rep generation. AutoBrep outperforms baselines with better quality and watertightness. It is also highly scalable to complex solids with good fidelity and inference speed. We further show that autocompleting B-Reps is natively supported through our unified tokenization, enabling user-controllable CAD generation with minimal changes. Code is available at https://github.com/AutodeskAILab/AutoBrep.",
        "abstract_summary_gcp": "The paper introduces **AutoBrep**, a novel Transformer model designed to overcome the challenge of directly generating precise and watertight Boundary Representations (B-Reps) in CAD. B-Reps are the standard data structure for solid models, but end-to-end generation with high quality and validity has been difficult.\n\nAutoBrep addresses this through a **unified tokenization scheme** that encodes both the geometric and topological characteristics of a B-Rep model into a sequence of discrete tokens. Geometric primitives (surfaces and curves) are represented as latent geometry tokens, while their structural relationships are captured by special topological reference tokens. The model autoregressively generates these B-Reps, following a breadth-first traversal of the B-Rep's face adjacency graph. During inference, it progressively generates neighboring faces, edges, and their topological structure using next-token prediction.\n\nExperiments show that AutoBrep outperforms baseline methods, producing B-Reps with better quality and watertightness. It also demonstrates high scalability for complex solids, maintaining good fidelity and inference speed. Additionally, its unified tokenization natively supports B-Rep autocompletion, enabling user-controllable CAD generation.",
        "url": "https://www.semanticscholar.org/paper/5c085e6bd81d651cb5e9241af162a7d81ebfafbd",
        "isOpenAccess": false
    },
    "2512.02567": {
        "title": "Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System",
        "authors": [
            "Martin Weiss",
            "Jesko Hecking-Harbusch",
            "Jochen Quante",
            "Matthias Woehrle"
        ],
        "arxiv_id": "2512.02567",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes. We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables. Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.",
        "abstract_summary_gcp": "This paper investigates the reliability of strong generative AI in automated software engineering tasks, specifically focusing on a C-to-Rust code translation system.\n\nThe translation system uses a \"generate-and-check\" approach: an LLM generates Rust code from C, which is then automatically checked for compilability and behavioral equivalence. If checks fail, the LLM is re-prompted in an automated feedback loop to correct its output.\n\nThe study examines the impact of three factors on translation quality:\n1.  **Automated feedback loops**\n2.  **The choice of Large Language Model (LLM)**\n3.  **Behavior-preserving code changes (perturbations)**\n\nKey findings include:\n*   Without feedback loops, LLM selection significantly affects translation success.\n*   However, when feedback loops are employed, the performance differences between various LLMs diminish considerably. This holds true for both average performance and robustness against code perturbations.\n*   Surprisingly, the diversity introduced by code perturbations can, in some cases, even lead to improved system performance.",
        "url": "https://www.semanticscholar.org/paper/e016ff9921d01ae1102d7a555dc95d7c82a26aca",
        "isOpenAccess": false
    },
    "2512.03001": {
        "title": "Invasive Context Engineering to Control Large Language Models",
        "authors": [
            "Thomas Rivasseau"
        ],
        "arxiv_id": "2512.03001",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.",
        "abstract_summary_gcp": "Current research enhances Large Language Model (LLM) robustness against adversarial attacks and misbehavior through methods like preference training, prompting, and input/output filtering. However, LLMs remain vulnerable to abuse, with jailbreak probability increasing with context length, highlighting a need for stronger security in long-context scenarios.\n\nTo address this, the authors propose \"Invasive Context Engineering\" (ICE): inserting control sentences directly into the LLM's context. This technique can partially mitigate long-context vulnerabilities and be extended to Chain-of-Thought processes to prevent \"scheming.\" A key advantage of ICE is that it doesn't require LLM retraining, thus avoiding the data shortage issues common when training models for long-context situations.",
        "url": "https://www.semanticscholar.org/paper/0c4b43949b314d225227966b70c92d43f01af886",
        "isOpenAccess": false
    },
    "2512.02743": {
        "title": "Reasoning-Aware Multimodal Fusion for Hateful Video Detection",
        "authors": [
            "Shuonan Yang",
            "Tailin Chen",
            "Jiangbei Yue",
            "Guangliang Cheng",
            "Jianbo Jiao",
            "Zeyu Fu"
        ],
        "arxiv_id": "2512.02743",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Hate speech in online videos is posing an increasingly serious threat to digital platforms, especially as video content becomes increasingly multimodal and context-dependent. Existing methods often struggle to effectively fuse the complex semantic relationships between modalities and lack the ability to understand nuanced hateful content. To address these issues, we propose an innovative Reasoning-Aware Multimodal Fusion (RAMF) framework. To tackle the first challenge, we design Local-Global Context Fusion (LGCF) to capture both local salient cues and global temporal structures, and propose Semantic Cross Attention (SCA) to enable fine-grained multimodal semantic interaction. To tackle the second challenge, we introduce adversarial reasoning-a structured three-stage process where a vision-language model generates (i) objective descriptions, (ii) hate-assumed inferences, and (iii) non-hate-assumed inferences-providing complementary semantic perspectives that enrich the model's contextual understanding of nuanced hateful intent. Evaluations on two real-world hateful video datasets demonstrate that our method achieves robust generalisation performance, improving upon state-of-the-art methods by 3% and 7% in Macro-F1 and hate class recall, respectively. We will release the code after the anonymity period ends.",
        "abstract_summary_gcp": "This paper addresses the growing threat of hate speech in online videos, where existing methods struggle with complex multimodal semantic fusion and understanding nuanced hateful content. The authors propose the **Reasoning-Aware Multimodal Fusion (RAMF)** framework.\n\nRAMF tackles these challenges by:\n1.  **Improving Multimodal Fusion:** It uses **Local-Global Context Fusion (LGCF)** to capture both local salient cues and global temporal structures, and **Semantic Cross Attention (SCA)** for fine-grained multimodal semantic interaction.\n2.  **Enhancing Nuance Understanding:** It introduces **adversarial reasoning**, a three-stage process where a vision-language model generates (i) objective descriptions, (ii) hate-assumed inferences, and (iii) non-hate-assumed inferences. This provides complementary perspectives to better grasp nuanced hateful intent.\n\nEvaluations on two real-world hateful video datasets demonstrate that RAMF achieves robust generalization, outperforming state-of-the-art methods by 3% in Macro-F1 and 7% in hate class recall.",
        "url": "https://www.semanticscholar.org/paper/4958080badf6fc8774f477a4bc2c157472547120",
        "isOpenAccess": false
    },
    "2512.02863": {
        "title": "Leveraging generative adversarial networks with spatially adaptive denormalization for multivariate stochastic seismic data inversion",
        "authors": [
            "R. Miele",
            "Leonardo Azevedo"
        ],
        "arxiv_id": "2512.02863",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Physics",
            "Computer Science",
            "Mathematics"
        ],
        "abstract": "Probabilistic seismic inverse modeling often requires the prediction of both spatially correlated geological heterogeneities (e.g., facies) and continuous parameters (e.g., rock and elastic properties). Generative adversarial networks (GANs) provide an efficient training-image-based simulation framework capable of reproducing complex geological models with high accuracy and comparably low generative cost. However, their application in stochastic geophysical inversion for multivariate property prediction is limited, as representing multiple coupled properties requires large and unstable networks with high memory and training demands. A more recent variant of GANs with spatially adaptive denormalization (SPADE-GAN) enables the direct conditioning of facies spatial distributions on local probability maps. Leveraging on such features, an iterative geostatistical inversion algorithm is proposed, SPADE-GANInv, integrating a pre-trained SPADE-GAN with geostatistical simulation, for the prediction of facies and multiple correlated continuous properties from seismic data. The SPADE-GAN is trained to reproduce realistic facies geometries, while sequential stochastic co-simulation predicts the spatial variability of the facies-dependent continuous properties. At each iteration, a set of subsurface realizations is generated and used to compute synthetic seismic data. The realizations providing the highest similarity coefficient to the observed data are used to update the subsurface probability models in the next iteration. The method is demonstrated on both 2-D synthetic scenarios and field data, targeting the prediction of facies, porosity, and acoustic impedance from full-stack seismic data. Results show that the algorithm enables accurate multivariate prediction, mitigates the impact of biased prior data, and accommodates additional local conditioning such as well logs.",
        "abstract_summary_gcp": "This paper introduces **SPADE-GANInv**, an iterative geostatistical inversion algorithm designed for probabilistic seismic inverse modeling. The method addresses the challenge of predicting both spatially correlated geological facies and continuous rock properties (like porosity or impedance) from seismic data.\n\nTraditional Generative Adversarial Networks (GANs), while efficient for simulating complex geology, struggle with multivariate property prediction due to their size and instability. SPADE-GANs, a newer variant, overcome some of these limitations by enabling direct conditioning of facies distributions on local probability maps.\n\nSPADE-GANInv leverages this capability by integrating a pre-trained SPADE-GAN (to generate realistic facies geometries) with sequential stochastic co-simulation (to predict facies-dependent continuous properties). The algorithm operates iteratively:\n1.  It generates multiple subsurface realizations.\n2.  Computes synthetic seismic data from these realizations.\n3.  Compares the synthetic data to observed seismic data using a similarity coefficient.\n4.  Uses the best-matching realizations to update the subsurface probability models for the next iteration.\n\nDemonstrated on both synthetic and field data for predicting facies, porosity, and acoustic impedance from full-stack seismic, SPADE-GANInv achieves accurate multivariate prediction. It also effectively mitigates the impact of biased prior data and can incorporate additional local conditioning from well logs.",
        "url": "https://www.semanticscholar.org/paper/6892a02efab33f7bd2f7c46e6448e9dde61d9c16",
        "isOpenAccess": false
    },
    "2512.02677": {
        "title": "Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks",
        "authors": [
            "Zhiyuan He"
        ],
        "arxiv_id": "2512.02677",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.",
        "abstract_summary_gcp": "This paper investigates a critical and underexplored limitation of Large Language Models (LLMs): **depth generalization**, their ability to handle problems with more nested hierarchical levels (e.g., parentheses in an expression) than seen during training.\n\nWhile LLMs perform well on many tasks and can generalize to longer sequences (length generalization), standard transformer architectures struggle significantly with deeper recursion, even if the overall sequence length is comparable to training data. This performance decay is attributed to their inability to maintain stack-like behavior, essential for tracking and resolving nested dependencies.\n\nTo address this, the authors propose a novel **looped locate-and-replace pipeline**. This method decomposes recursive problems into manageable subcomponents using two specialized models: a \"locator\" to identify solvable subexpressions and a \"replacer\" to evaluate them while preserving the overall structure.\n\nEvaluated in three domains (Boolean algebra, recursive arithmetic, and propositional logic) with controllable recursion depth, the proposed method effectively mitigates the performance decay observed in LLMs when faced with out-of-distribution recursion depths.",
        "url": "https://www.semanticscholar.org/paper/23673e4c973a4ab21d6cd433e0738c0054778c09",
        "isOpenAccess": false
    },
    "2512.02557": {
        "title": "Deep Learning-Based Joint Uplink-Downlink CSI Acquisition for Next-Generation Upper Mid-Band Systems",
        "authors": [
            "Xuan He",
            "Hongwei Hou",
            "Yafei Wang",
            "Wenjin Wang",
            "Shi Jin",
            "S. Chatzinotas",
            "Björn E. Ottersten"
        ],
        "arxiv_id": "2512.02557",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Engineering"
        ],
        "abstract": "In next-generation wireless communication systems, the newly designated upper mid-band has attracted considerable attention, also called frequency range 3 (FR3), highlighting the need for downlink (DL) transmission design, which fundamentally relies on accurate CSI. However, CSI acquisition in FR3 systems faces significant challenges: the increased number of antennas and wider transmission bandwidth introduces prohibitive training overhead with traditional estimation approaches, as each probing captures only incomplete spatial-frequency observation, while higher carrier frequencies lead to faster temporal channel variation. To address these challenges, we propose a novel CSI acquisition framework that integrates CSI feedback, uplink (UL) and DL channel estimation, as well as channel prediction in the FR3 TDD massive MIMO systems. Specifically, we first develop the Joint UL and DL Channel Estimation Network (JUDCEN) to fuse incomplete observations based on the SRSs and CSI-RSs. By exploiting the complementary characteristics of preliminary UL and DL estimation features, obtained through initial UL estimation and quantized-feedback-assisted DL estimation, it enables full CSI reconstruction in the spatial domain. To mitigate the performance degradation in the feedback process, we propose the Transformer-MLP CSI Feedback Network (TMCFN), employing an MLP-based module to jointly exploit angle- and delay-domain features. Building upon the reconstructed full CSI, we further develop the Mamba-based Channel Prediction Network (MCPN), which exploits selective state-space model (SSM) mechanism to capture long-range temporal dynamics in the angle-delay domain for future CSI prediction. Simulation results demonstrate that the proposed framework consistently outperforms benchmarks in both CSI acquisition accuracy and transmission spectral efficiency with lower computational complexity.",
        "abstract_summary_gcp": "In next-generation Frequency Range 3 (FR3) massive MIMO systems, accurate Downlink (DL) Channel State Information (CSI) is vital but challenging to acquire. The difficulties stem from the large number of antennas and wide transmission bandwidth, leading to prohibitive training overhead with traditional methods, and faster temporal channel variations due to higher carrier frequencies.\n\nTo overcome these challenges, the authors propose a novel CSI acquisition framework for FR3 TDD massive MIMO systems. This framework integrates CSI feedback, uplink (UL) and DL channel estimation, and channel prediction, featuring three key components:\n\n1.  **Joint UL and DL Channel Estimation Network (JUDCEN):** This network fuses incomplete observations from Sounding Reference Signals (SRSs) and CSI Reference Signals (CSI-RSs). By exploiting the complementary characteristics of preliminary UL and quantized-feedback-assisted DL estimation, JUDCEN enables full CSI reconstruction in the spatial domain.\n2.  **Transformer-MLP CSI Feedback Network (TMCFN):** Designed to mitigate performance degradation during the feedback process, TMCFN uses an MLP-based module to jointly extract and leverage features from both the angle- and delay-domains.\n3.  **Mamba-based Channel Prediction Network (MCPN):** Building upon the reconstructed full CSI, MCPN utilizes a selective state-space model (SSM) mechanism to capture long-range temporal dynamics in the angle-delay domain, enabling accurate prediction of future CSI.\n\nSimulation results demonstrate that the proposed framework consistently outperforms benchmark approaches in terms of CSI acquisition accuracy, transmission spectral efficiency, and computational complexity.",
        "url": "https://www.semanticscholar.org/paper/88a2ff205fdb97c45b2170ee0d05d671f22791aa",
        "isOpenAccess": false
    },
    "2512.02710": {
        "title": "Beyond N-grams: A Hierarchical Reward Learning Framework for Clinically-Aware Medical Report Generation",
        "authors": [
            "Yuan Wang",
            "Shujian Gao",
            "Jiaxiang Liu",
            "Songtao Jiang",
            "Haoxiang Xia",
            "Xiaotian Zhang",
            "Zhaolu Kang",
            "Yemin Wang",
            "Zuozhu Liu"
        ],
        "arxiv_id": "2512.02710",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Automatic medical report generation can greatly reduce the workload of doctors, but it is often unreliable for real-world deployment. Current methods can write formally fluent sentences but may be factually flawed, introducing serious medical errors known as clinical hallucinations, which make them untrustworthy for diagnosis. To bridge this gap, we introduce HiMed-RL, a Hierarchical Medical Reward Learning Framework designed to explicitly prioritize clinical quality. HiMed-RL moves beyond simple text matching by deconstructing reward learning into three synergistic levels: it first ensures linguistic fluency at the token-level, then enforces factual grounding at the concept-level by aligning key medical terms with expert knowledge, and finally assesses high-level diagnostic consistency at the semantic-level using a specialized LLM verifier. This hierarchical reward is implemented via a Human-inspired Dynamic Reward Adjustment, a strategy which first teaches the model to learn basic facts before progressing to more complex diagnostic reasoning. Experimentally, HiMed-3B achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks, particularly on the latter, with an improvement of 12.1% over the second-best baseline. Our work provides a robust paradigm for generating reports that not only improve fluency but clinical fine-grained quality.",
        "abstract_summary_gcp": "This paper introduces **HiMed-RL (Hierarchical Medical Reward Learning Framework)**, a solution designed to address the critical issue of \"clinical hallucinations\" – factual errors – in automatic medical report generation. While current methods can produce fluent text, their unreliability due to these errors makes them untrustworthy for diagnosis.\n\nHiMed-RL explicitly prioritizes clinical quality by deconstructing reward learning into three synergistic levels:\n1.  **Token-level:** Ensures linguistic fluency.\n2.  **Concept-level:** Enforces factual grounding by aligning key medical terms with expert knowledge.\n3.  **Semantic-level:** Assesses high-level diagnostic consistency using a specialized LLM verifier.\n\nThis hierarchical reward system is implemented via a **Human-inspired Dynamic Reward Adjustment**, which progressively teaches the model from basic facts to more complex diagnostic reasoning. Experimentally, HiMed-3B achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks, demonstrating a significant 12.1% improvement over the second-best baseline on out-of-domain tasks. The work offers a robust paradigm for generating medical reports that are not only fluent but also clinically accurate and reliable.",
        "url": "https://www.semanticscholar.org/paper/1e4390393ee1daa02bf15bbdfc4f288811ab8377",
        "isOpenAccess": false
    },
    "2512.02712": {
        "title": "G-PIFNN: A Generalizable Physics-informed Fourier Neural Network Framework for Electrical Circuits",
        "authors": [
            "Ibrahim Shahbaz",
            "Mohammad J. Abdel-Rahman",
            "Eman Hammad"
        ],
        "arxiv_id": "2512.02712",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Engineering"
        ],
        "abstract": "Physics-Informed Neural Networks (PINNs) have advanced the data-driven solution of differential equations (DEs) in dynamic physical systems, yet challenges remain in explainability, scalability, and architectural complexity. This paper presents a Generalizable Physics-Informed Fourier Neural Network (G-PIFNN) framework that enhances PINN architectures for efficient and interpretable electrical circuit analysis. The proposed G-PIFNN introduces three key advancements: (1) improved performance and interpretability via a physics activation function (PAF) and a lightweight Physics-Informed Fourier Neural Network (PIFNN) architecture; (2) automated, bond graph (BG) based formulation of physics-informed loss functions for systematic differential equation generation; and (3) integration of intra-circuit and cross-circuit class transfer learning (TL) strategies, enabling unsupervised fine-tuning for rapid adaptation to varying circuit topologies. Numerical simulations demonstrate that G-PIFNN achieves significantly better predictive performance and generalization across diverse circuit classes, while significantly reducing the number of trainable parameters compared to standard PINNs.",
        "abstract_summary_gcp": "This paper introduces the Generalizable Physics-Informed Fourier Neural Network (G-PIFNN) framework, an advancement over traditional Physics-Informed Neural Networks (PINNs) designed to overcome challenges in explainability, scalability, and complexity when solving differential equations in dynamic physical systems, particularly for electrical circuit analysis.\n\nG-PIFNN incorporates three key innovations:\n1.  **Improved Performance and Interpretability:** Achieved through a lightweight Physics-Informed Fourier Neural Network (PIFNN) architecture and a novel Physics Activation Function (PAF).\n2.  **Automated Loss Function Formulation:** Utilizes a bond graph (BG)-based approach for systematic generation of physics-informed loss functions and differential equations.\n3.  **Enhanced Adaptability:** Integrates intra-circuit and cross-circuit class transfer learning strategies, allowing for rapid, unsupervised fine-tuning and adaptation to diverse circuit topologies.\n\nNumerical simulations confirm that G-PIFNN significantly boosts predictive performance and generalization across various circuit classes, while concurrently reducing the number of trainable parameters compared to standard PINNs.",
        "url": "https://www.semanticscholar.org/paper/d9016c53c2cf3370ccb3264b250bd8dc535c13a7",
        "isOpenAccess": false
    },
    "2512.02643": {
        "title": "Leveraging Large-Scale Pretrained Spatial-Spectral Priors for General Zero-Shot Pansharpening",
        "authors": [
            "Yongchuan Cui",
            "Peng Liu",
            "Yi Zeng"
        ],
        "arxiv_id": "2512.02643",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Existing deep learning methods for remote sensing image fusion often suffer from poor generalization when applied to unseen datasets due to the limited availability of real training data and the domain gap between different satellite sensors. To address this challenge, we explore the potential of foundation models by proposing a novel pretraining strategy that leverages large-scale simulated datasets to learn robust spatial-spectral priors. Specifically, our approach first constructs diverse simulated datasets by applying various degradation operations (blur, noise, downsampling) and augmentations (bands generation, channel shuffling, high-pass filtering, color jittering, etc.) to natural images from ImageNet and remote sensing images from SkyScript. We then pretrain fusion models on these simulated data to learn generalizable spatial-spectral representations. The pretrained models are subsequently evaluated on six datasets (WorldView-2/3/4, IKONOS, QuickBird, GaoFen-2) using zero-shot and one-shot paradigms, with both full- and freeze-tuning approaches for fine-tuning. Extensive experiments on different network architectures including convolutional neural networks, Transformer, and Mamba demonstrate that our pretraining strategy significantly improves generalization performance across different satellite sensors and imaging conditions for various fusion models. The pretrained models achieve superior results in zero-shot scenarios and show remarkable adaptation capability with minimal real data in one-shot settings. Our work provides a practical solution for cross-domain pansharpening, establishes a new benchmark for generalization in remote sensing image fusion tasks, and paves the way for leveraging foundation models through advanced training strategies.",
        "abstract_summary_gcp": "Existing deep learning methods for remote sensing image fusion often struggle with poor generalization to new datasets due to limited real training data and the domain gap between different satellite sensors.\n\nTo address this, the authors propose a novel pretraining strategy that leverages foundation models. Their approach involves:\n1.  **Constructing large-scale simulated datasets:** This is done by applying various degradation operations (blur, noise, downsampling) and augmentations (bands generation, channel shuffling, high-pass filtering, color jittering) to both natural images (ImageNet) and remote sensing images (SkyScript).\n2.  **Pretraining fusion models:** Models are pretrained on these diverse simulated datasets to learn robust and generalizable spatial-spectral representations.\n\nThe pretrained models, including convolutional neural networks, Transformers, and Mamba architectures, were evaluated on six real-world datasets (WorldView-2/3/4, IKONOS, QuickBird, GaoFen-2). Experiments demonstrated that this pretraining strategy significantly improves generalization performance across different satellite sensors and imaging conditions. The models achieved superior results in zero-shot scenarios and showed remarkable adaptation capabilities with minimal real data in one-shot settings.\n\nThis work offers a practical solution for cross-domain pansharpening, establishes a new benchmark for generalization in remote sensing image fusion, and paves the way for leveraging foundation models through advanced training strategies.",
        "url": "https://www.semanticscholar.org/paper/7e9e2dd7cea8ba7847f99d736e443e4afee22eed",
        "isOpenAccess": false
    },
    "2512.02419": {
        "title": "The brain-AI convergence: Predictive and generative world models for general-purpose computation",
        "authors": [
            "Shogo Ohmae",
            "Keiko Ohmae"
        ],
        "arxiv_id": "2512.02419",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Biology",
            "Computer Science"
        ],
        "abstract": "Recent advances in general-purpose AI systems with attention-based transformers offer a potential window into how the neocortex and cerebellum, despite their relatively uniform circuit architectures, give rise to diverse functions and, ultimately, to human intelligence. This Perspective provides a cross-domain comparison between the brain and AI that goes beyond the traditional focus on visual processing, adopting the emerging perspecive of world-model-based computation. Here, we identify shared computational mechanisms in the attention-based neocortex and the non-attentional cerebellum: both predict future world events from past inputs and construct internal world models through prediction-error learning. These predictive world models are repurposed for seemingly distinct functions -- understanding in sensory processing and generation in motor processing -- enabling the brain to achieve multi-domain capabilities and human-like adaptive intelligence. Notably, attention-based AI has independently converged on a similar learning paradigm and world-model-based computation. We conclude that these shared mechanisms in both biological and artificial systems constitute a core computational foundation for realizing diverse functions including high-level intelligence, despite their relatively uniform circuit structures. Our theoretical insights bridge neuroscience and AI, advancing our understanding of the computational essence of intelligence.",
        "abstract_summary_gcp": "This Perspective proposes that recent advances in attention-based AI offer insights into how the neocortex and cerebellum, despite uniform circuit architectures, generate diverse functions and intelligence. It highlights a shared computational foundation: **world-model-based computation**.\n\nBoth the attention-based neocortex and the non-attentional cerebellum build internal world models by predicting future events from past inputs and employing prediction-error learning. These predictive models are then repurposed for distinct functions—understanding in sensory processing and generation in motor processing—enabling the brain's multi-domain capabilities and adaptive intelligence.\n\nNotably, attention-based AI has independently converged on this same learning paradigm and world-model-based computation. The authors conclude that these shared mechanisms constitute a core computational foundation for diverse functions and high-level intelligence in both biological and artificial systems, bridging neuroscience and AI.",
        "url": "https://www.semanticscholar.org/paper/472c12b4ba8fb8d256a603a9607ee37f98c385aa",
        "isOpenAccess": false
    },
    "2512.02368": {
        "title": "Multi-Domain Enhanced Map-Free Trajectory Prediction with Selective Attention",
        "authors": [
            "Wenyi Xiong",
            "Jian Chen"
        ],
        "arxiv_id": "2512.02368",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Trajectory prediction is crucial for the reliability and safety of autonomous driving systems, yet it remains a challenging task in complex interactive scenarios. Existing methods often struggle to efficiently extract valuable scene information from redundant data, thereby reducing computational efficiency and prediction accuracy, especially when dealing with intricate agent interactions. To address these challenges, we propose a novel map-free trajectory prediction algorithm that achieves trajectory prediction across the temporal, spatial, and frequency domains. Specifically, in temporal information processing, We utilize a Mixture of Experts (MoE) mechanism to adaptively select critical frequency components. Concurrently, we extract these components and integrate multi-scale temporal features. Subsequently, a selective attention module is proposed to filter out redundant information in both temporal sequences and spatial interactions. Finally, we design a multimodal decoder. Under the supervision of patch-level and point-level losses, we obtain reasonable trajectory results. Experiments on Nuscences datasets demonstrate the superiority of our algorithm, validating its effectiveness in handling complex interactive scenarios.",
        "abstract_summary_gcp": "This paper addresses the challenges in trajectory prediction for autonomous driving, particularly in complex interactive scenarios where existing methods struggle with redundant scene information, leading to reduced efficiency and accuracy.\n\nThe authors propose a novel **map-free trajectory prediction algorithm** that operates across temporal, spatial, and frequency domains. Key components include:\n1.  A **Mixture of Experts (MoE) mechanism** for temporal processing, which adaptively selects critical frequency components and integrates multi-scale temporal features.\n2.  A **selective attention module** designed to filter out redundant information from both temporal sequences and spatial interactions.\n3.  A **multimodal decoder** that, supervised by patch-level and point-level losses, generates reasonable trajectory results.\n\nExperiments on the NuScenes dataset demonstrate the algorithm's superior performance and effectiveness in handling complex interactive autonomous driving scenarios.",
        "url": "https://www.semanticscholar.org/paper/d3486f916e7a7b3694d7a617e4e9493f2e6ea644",
        "isOpenAccess": false
    },
    "2512.02558": {
        "title": "Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance",
        "authors": [
            "Yufei Xiao",
            "Shangfei Wang"
        ],
        "arxiv_id": "2512.02558",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Prevalent empathy prediction techniques primarily concentrate on a singular modality, typically textual, thus neglecting multi-modal processing capabilities. They also overlook the utilization of certain privileged information, which may encompass additional empathetic content. In response, we introduce an advanced multi-modal empathy prediction method integrating video, audio, and text information. The method comprises the Multi-Modal Empathy Prediction and Supervisory Documentation Assisted Training. We use pre-trained networks in the empathy prediction network to extract features from various modalities, followed by a cross-modal fusion. This process yields a multi-modal feature representation, which is employed to predict empathy labels. To enhance the extraction of text features, we incorporate supervisory documents as privileged information during the assisted training phase. Specifically, we apply the Latent Dirichlet Allocation model to identify potential topic distributions to constrain text features. These supervisory documents, created by supervisors, focus on the counseling topics and the counselor's display of empathy. Notably, this privileged information is only available during training and is not accessible during the prediction phase. Experimental results on the multi-modal and dialogue empathy datasets demonstrate that our approach is superior to the existing methods.",
        "abstract_summary_gcp": "Current empathy prediction methods are limited by their focus on single modalities (primarily text) and their neglect of \"privileged information.\" To overcome this, the paper introduces an advanced multi-modal empathy prediction method that integrates video, audio, and text.\n\nThe proposed approach consists of two main parts:\n1.  **Multi-Modal Empathy Prediction:** This network uses pre-trained models to extract features from video, audio, and text, which are then combined through cross-modal fusion to create a unified representation for predicting empathy.\n2.  **Supervisory Documentation Assisted Training:** To improve text feature extraction, \"supervisory documents\" (created by supervisors, detailing counseling topics and empathy displays) are utilized as privileged information *during the training phase only*. This involves applying Latent Dirichlet Allocation (LDA) to these documents to constrain and enhance the textual features.\n\nExperimental results on multi-modal and dialogue empathy datasets demonstrate that this new approach surpasses existing methods.",
        "url": "https://www.semanticscholar.org/paper/5d5a7e15bb4e8a1757b1d2b1d84a960a30f78c95",
        "isOpenAccess": false
    },
    "2512.03040": {
        "title": "Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation",
        "authors": [
            "Zeqi Xiao",
            "Yiwei Zhao",
            "Lingxiao Li",
            "Yushi Lan",
            "Yu Ning",
            "Rahul Garg",
            "Roshni Cooper",
            "M. H. Taghavi",
            "Xingang Pan"
        ],
        "arxiv_id": "2512.03040",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires semantic localization, instruction following, and planning. Both tasks use video-only inputs, without auxiliary modalities such as depth or poses. With simple yet effective design choices in the framework and data curation, Video4Spatial demonstrates strong spatial understanding from video context: it plans navigation and grounds target objects end-to-end, follows camera-pose instructions while maintaining spatial consistency, and generalizes to long contexts and out-of-domain environments. Taken together, these results advance video generative models toward general visuospatial reasoning.",
        "abstract_summary_gcp": "This paper introduces **Video4Spatial**, a framework demonstrating that video generative models can exhibit visuospatial intelligence using *only visual data*.\n\nVideo4Spatial leverages video diffusion models conditioned solely on video-based scene context to perform complex spatial tasks. It is validated on two primary tasks:\n1.  **Scene Navigation:** Following camera-pose instructions while maintaining consistency with the 3D geometry of the scene.\n2.  **Object Grounding:** Requiring semantic localization, instruction following, and planning.\n\nCrucially, both tasks rely exclusively on video-only inputs, without any auxiliary modalities like depth maps or camera poses. Through simple yet effective design choices and data curation, Video4Spatial achieves strong spatial understanding, capable of planning navigation, grounding objects end-to-end, following camera-pose instructions consistently, and generalizing to long contexts and out-of-domain environments. These results significantly advance video generative models towards general visuospatial reasoning.",
        "url": "https://www.semanticscholar.org/paper/a46cf6f4a20c0c6e1beefb2d397d5f422d1281ab",
        "isOpenAccess": false
    },
    "2512.02789": {
        "title": "TrackNetV5: Residual-Driven Spatio-Temporal Refinement and Motion Direction Decoupling for Fast Object Tracking",
        "authors": [
            "Haonan Tang",
            "Yanjun Chen",
            "Jiang Lezhi"
        ],
        "arxiv_id": "2512.02789",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "The TrackNet series has established a strong baseline for fast-moving small object tracking in sports. However, existing iterations face significant limitations: V1-V3 struggle with occlusions due to a reliance on purely visual cues, while TrackNetV4, despite introducing motion inputs, suffers from directional ambiguity as its absolute difference method discards motion polarity. To overcome these bottlenecks, we propose TrackNetV5, a robust architecture integrating two novel mechanisms. First, to recover lost directional priors, we introduce the Motion Direction Decoupling (MDD) module. Unlike V4, MDD decomposes temporal dynamics into signed polarity fields, explicitly encoding both movement occurrence and trajectory direction. Second, we propose the Residual-Driven Spatio-Temporal Refinement (R-STR) head. Operating on a coarse-to-fine paradigm, this Transformer-based module leverages factorized spatio-temporal contexts to estimate a corrective residual, effectively recovering occluded targets. Extensive experiments on the TrackNetV2 dataset demonstrate that TrackNetV5 achieves a new state-of-the-art F1-score of 0.9859 and an accuracy of 0.9733, significantly outperforming previous versions. Notably, this performance leap is achieved with a marginal 3.7% increase in FLOPs compared to V4, maintaining real-time inference capabilities while delivering superior tracking precision.",
        "abstract_summary_gcp": "TrackNetV5 is a new architecture for fast-moving small object tracking in sports, designed to overcome limitations of previous versions. Earlier iterations (V1-V3) struggled with occlusions due to their reliance on purely visual cues, while TrackNetV4, despite using motion, suffered from directional ambiguity by discarding motion polarity.\n\nTrackNetV5 introduces two key innovations:\n\n1.  **Motion Direction Decoupling (MDD) module:** This module recovers lost directional priors by decomposing temporal dynamics into signed polarity fields, explicitly encoding both movement occurrence and trajectory direction, unlike V4's absolute difference method.\n2.  **Residual-Driven Spatio-Temporal Refinement (R-STR) head:** A Transformer-based module that operates on a coarse-to-fine paradigm, leveraging factorized spatio-temporal contexts to estimate a corrective residual, which effectively recovers occluded targets.\n\nExtensive experiments on the TrackNetV2 dataset demonstrate that TrackNetV5 achieves state-of-the-art performance with an F1-score of 0.9859 and an accuracy of 0.9733, significantly outperforming previous versions. This performance leap is achieved with only a marginal 3.7% increase in FLOPs compared to TrackNetV4, maintaining real-time inference capabilities.",
        "url": "https://www.semanticscholar.org/paper/3209d5a0d0602ef2f50c46f67c41d1a29fb0afd7",
        "isOpenAccess": false
    },
    "2512.02319": {
        "title": "Associative Memory using Attribute-Specific Neuron Groups-1: Learning between Multiple Cue Balls",
        "authors": [
            "Hiroshi Inazawa"
        ],
        "arxiv_id": "2512.02319",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "In this paper, we present a new neural network model based on attribute-specific representations (e.g., color, shape, size), a classic example of associative memory. The proposed model is based on a previous study on memory and recall of multiple images using the Cue Ball and Recall Net (referred to as the CB-RN system, or simply CB-RN) [1]. The system consists of three components, which are C.CB-RN for processing color, S.CB-RN for processing shape, and V.CB-RN for processing size. When an attribute data pattern is presented to the CB-RN system, the corresponding attribute pattern of the cue neurons within the Cue Balls is associatively recalled in the Recall Net. Each image pattern presented to these CB-RN systems is represented using a two-dimensional code, specifically a QR code [2].",
        "abstract_summary_gcp": "This paper introduces a new neural network model designed for associative memory, specifically utilizing attribute-specific representations (like color, shape, and size). The model is an extension of the existing Cue Ball and Recall Net (CB-RN) system and is structured into three specialized components: C.CB-RN for color, S.CB-RN for shape, and V.CB-RN for size. When an attribute data pattern is presented, the system associatively recalls the corresponding attribute pattern via cue neurons within the Recall Net. All image patterns processed by these CB-RN systems are represented using two-dimensional QR codes.",
        "url": "https://www.semanticscholar.org/paper/98b8d232874c4271149106d6cfdc8e60e3d279f0",
        "isOpenAccess": false
    },
    "2512.02465": {
        "title": "TabGRU: An Enhanced Design for Urban Rainfall Intensity Estimation Using Commercial Microwave Links",
        "authors": [
            "Xingwang Li",
            "Mengyun Chen",
            "Jiamou Liu",
            "Sijie Wang",
            "Shuanggen Jin",
            "J. C. Andersson",
            "Jonas Olsson",
            "Remco van de Beek",
            "H. Habi",
            "Congzheng Han"
        ],
        "arxiv_id": "2512.02465",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "In the face of accelerating global urbanization and the increasing frequency of extreme weather events, highresolution urban rainfall monitoring is crucial for building resilient smart cities. Commercial Microwave Links (CMLs) are an emerging data source with great potential for this task.While traditional rainfall retrieval from CMLs relies on physicsbased models, these often struggle with real-world complexities like signal noise and nonlinear attenuation. To address these limitations, this paper proposes a novel hybrid deep learning architecture based on the Transformer and a Bidirectional Gated Recurrent Unit (BiGRU), which we name TabGRU. This design synergistically captures both long-term dependencies and local sequential features in the CML signal data. The model is further enhanced by a learnable positional embedding and an attention pooling mechanism to improve its dynamic feature extraction and generalization capabilities. The model was validated on a public benchmark dataset from Gothenburg, Sweden (June-September 2015). The evaluation used 12 sub-links from two rain gauges (Torp and Barl) over a test period (August 22-31) covering approximately 10 distinct rainfall events. The proposed TabGRU model demonstrated consistent advantages, outperforming deep learning baselines and achieving high coefficients of determination (R2) at both the Torp site (0.91) and the Barl site (0.96). Furthermore, compared to the physics-based approach, TabGRU maintained higher accuracy and was particularly effective in mitigating the significant overestimation problem observed in the PL model during peak rainfall events. This evaluation confirms that the TabGRU model can effectively overcome the limitations of traditional methods, providing a robust and accurate solution for CML-based urban rainfall monitoring under the tested conditions.",
        "abstract_summary_gcp": "This paper proposes a novel hybrid deep learning model called TabGRU for high-resolution urban rainfall monitoring using Commercial Microwave Links (CMLs). Addressing the limitations of traditional physics-based models (signal noise, non-linear attenuation) in real-world scenarios, TabGRU combines a Transformer for long-term dependencies and a Bidirectional Gated Recurrent Unit (BiGRU) for local sequential features. It's further enhanced with learnable positional embedding and attention pooling for dynamic feature extraction and generalization.\n\nValidated on a benchmark dataset from Gothenburg, Sweden, TabGRU consistently outperformed deep learning baselines and achieved high coefficients of determination (R2) of 0.91 (Torp) and 0.96 (Barl). Crucially, it also demonstrated higher accuracy than physics-based approaches, particularly excelling at mitigating the overestimation problem during peak rainfall events. The study concludes that TabGRU offers a robust and accurate solution for CML-based urban rainfall monitoring under the tested conditions.",
        "url": "https://www.semanticscholar.org/paper/8f04a236da522f237e27ba7126ea385401242a5d",
        "isOpenAccess": false
    },
    "2512.02392": {
        "title": "From Detection to Association: Learning Discriminative Object Embeddings for Multi-Object Tracking",
        "authors": [
            "Yuqing Shao",
            "Yuchen Yang",
            "Rui Yu",
            "Weilong Li",
            "Xu Guo",
            "Huaicheng Yan",
            "Wei Wang",
            "Xiao Sun"
        ],
        "arxiv_id": "2512.02392",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "End-to-end multi-object tracking (MOT) methods have recently achieved remarkable progress by unifying detection and association within a single framework. Despite their strong detection performance, these methods suffer from relatively low association accuracy. Through detailed analysis, we observe that object embeddings produced by the shared DETR architecture display excessively high inter-object similarity, as it emphasizes only category-level discrimination within single frames. In contrast, tracking requires instance-level distinction across frames with spatial and temporal continuity, for which current end-to-end approaches insufficiently optimize object embeddings. To address this, we introduce FDTA (From Detection to Association), an explicit feature refinement framework that enhances object discriminativeness across three complementary perspectives. Specifically, we introduce a Spatial Adapter (SA) to integrate depth-aware cues for spatial continuity, a Temporal Adapter (TA) to aggregate historical information for temporal dependencies, and an Identity Adapter (IA) to leverage quality-aware contrastive learning for instance-level separability. Extensive experiments demonstrate that FDTA achieves state-of-the-art performance on multiple challenging MOT benchmarks, including DanceTrack, SportsMOT, and BFT, highlighting the effectiveness of our proposed discriminative embedding enhancement strategy. The code is available at https://github.com/Spongebobbbbbbbb/FDTA.",
        "abstract_summary_gcp": "This paper addresses a key limitation in end-to-end multi-object tracking (MOT) methods: despite strong detection performance, they suffer from low association accuracy. The authors identify that shared DETR-based architectures produce object embeddings with excessively high inter-object similarity, as they primarily focus on category-level discrimination within single frames, rather than the instance-level distinction and spatio-temporal continuity essential for robust tracking.\n\nTo resolve this, they introduce FDTA (From Detection to Association), an explicit feature refinement framework designed to significantly enhance object discriminativeness. FDTA incorporates three complementary modules:\n1.  **Spatial Adapter (SA):** Integrates depth-aware cues to improve spatial continuity.\n2.  **Temporal Adapter (TA):** Aggregates historical information to strengthen temporal dependencies.\n3.  **Identity Adapter (IA):** Leverages quality-aware contrastive learning to boost instance-level separability.\n\nExtensive experiments show that FDTA achieves state-of-the-art performance on challenging MOT benchmarks like DanceTrack, SportsMOT, and BFT, demonstrating the effectiveness of its proposed discriminative embedding enhancement strategy.",
        "url": "https://www.semanticscholar.org/paper/7cdbbcccbf75d24b85c2e85d42a895e6483b4dd0",
        "isOpenAccess": false
    },
    "2512.02403": {
        "title": "ESACT: An End-to-End Sparse Accelerator for Compute-Intensive Transformers via Local Similarity",
        "authors": [
            "Hongxiang Liu",
            "Zhifang Deng",
            "Tong Pu",
            "Shengli Lu"
        ],
        "arxiv_id": "2512.02403",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Transformers, composed of QKV generation, attention computation, and FFNs, have become the dominant model across various domains due to their outstanding performance. However, their high computational cost hinders efficient hardware deployment. Sparsity offers a promising solution, yet most existing accelerators exploit only intra-row sparsity in attention, while few consider inter-row sparsity. Approaches leveraging inter-row sparsity often rely on costly global similarity estimation, which diminishes the acceleration benefits of sparsity, and typically apply sparsity to only one or two transformer components. Through careful analysis of the attention distribution and computation flow, we observe that local similarity allows end-to-end sparse acceleration with lower computational overhead. Motivated by this observation, we propose ESACT, an end-to-end sparse accelerator for compute-intensive Transformers. ESACT centers on the Sparsity Prediction with Local Similarity (SPLS) mechanism, which leverages HLog quantization to accurately predict local attention sparsity prior to QK generation, achieving efficient sparsity across all transformer components. To support efficient hardware realization, we introduce three architectural innovations. Experimental results on 26 benchmarks demonstrate that SPLS reduces total computation by 52.03% with less than 1% accuracy loss. ESACT achieves an end-to-end energy efficiency of 3.29 TOPS/W, and improves attention-level energy efficiency by 2.95x and 2.26x over SOTA attention accelerators SpAtten and Sanger, respectively.",
        "abstract_summary_gcp": "Transformers, while powerful, are computationally expensive, hindering efficient hardware deployment. Existing sparsity solutions are limited: most exploit only intra-row sparsity, while inter-row methods rely on costly global similarity estimation and typically apply sparsity to only a few components.\n\nThis paper observes that *local similarity* allows for more efficient end-to-end sparse acceleration. Based on this, they propose **ESACT**, an end-to-end sparse accelerator centered on the **Sparsity Prediction with Local Similarity (SPLS)** mechanism. SPLS uses HLog quantization to predict local attention sparsity *before* QK generation, enabling efficient sparsity across *all* Transformer components. ESACT also incorporates three architectural innovations for hardware efficiency.\n\nExperiments demonstrate that SPLS reduces total computation by 52.03% with less than 1% accuracy loss. ESACT achieves 3.29 TOPS/W end-to-end energy efficiency and significantly outperforms state-of-the-art attention accelerators in energy efficiency (2.95x over SpAtten and 2.26x over Sanger).",
        "url": "https://www.semanticscholar.org/paper/83e332b5133411ff0b75de332606be72f8095ab7",
        "isOpenAccess": false
    },
    "2512.02700": {
        "title": "VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm",
        "authors": [
            "Zhenkai Wu",
            "Xiaowen Ma",
            "Zhenliang Ni",
            "Dengming Zhang",
            "Han Shu",
            "Xin Jiang",
            "Xinghao Chen"
        ],
        "arxiv_id": "2512.02700",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Vision-language models (VLMs) excel at image understanding tasks, but the large number of visual tokens imposes significant computational costs, hindering deployment on mobile devices. Many pruning methods rely solely on token importance and thus overlook inter-token redundancy, retaining numerous duplicated tokens and wasting capacity. Although some redundancy-aware approaches have been proposed, they often ignore the spatial relationships among visual tokens. This can lead to overly sparse selections of retained tokens that fail to adequately cover the regions of target objects. To address these limitations, we propose VLM-Pruner, a training-free token pruning algorithm that explicitly balances redundancy and spatial sparsity. We introduce a centrifugal token pruning paradigm that enables near-to-far selection while prioritizing the preservation of fine-grained object details. Moreover, we design a Buffering for Spatial Sparsity (BSS) criterion that defers the selection of spatially distant tokens. We further adopt a parallel greedy strategy to conduct token selection efficiently. To mitigate information loss from pruning, we selectively fuse salient information from the discarded tokens into the retained ones. Comprehensive comparisons demonstrate that VLM-Pruner consistently outperforms strong baselines across five VLMs with an 88.9\\% pruning rate, while delivering an end-to-end inference speedup.",
        "abstract_summary_gcp": "This paper introduces **VLM-Pruner**, a training-free token pruning algorithm designed to optimize Vision-Language Models (VLMs) by significantly reducing computational costs without sacrificing performance.\n\nThe core problem VLM-Pruner addresses is the inefficiency of existing pruning methods. Current approaches either:\n1.  Focus solely on token importance, leading to the retention of redundant tokens and wasted capacity.\n2.  Are redundancy-aware but ignore spatial relationships, resulting in overly sparse selections that fail to adequately cover target objects.\n\nVLM-Pruner tackles these limitations by explicitly balancing redundancy and spatial sparsity through several key innovations:\n*   **Centrifugal Token Pruning Paradigm:** It employs a novel near-to-far selection strategy that prioritizes the preservation of fine-grained object details.\n*   **Buffering for Spatial Sparsity (BSS) Criterion:** This mechanism intelligently defers the selection of spatially distant tokens, ensuring better coverage of object regions.\n*   **Parallel Greedy Strategy:** This is adopted for efficient token selection.\n*   **Information Fusion:** To mitigate potential information loss from discarded tokens, VLM-Pruner selectively fuses salient information from them into the retained tokens.\n\nComprehensive evaluations demonstrate that VLM-Pruner consistently outperforms strong baseline methods across five different VLMs, achieving an impressive **88.9% pruning rate** while simultaneously delivering significant **end-to-end inference speedup**.",
        "url": "https://www.semanticscholar.org/paper/31b2ace1b3c7ea66db054dadf79c67947f937e68",
        "isOpenAccess": false
    },
    "2512.02369": {
        "title": "SAGE: Style-Adaptive Generalization for Privacy-Constrained Semantic Segmentation Across Domains",
        "authors": [
            "Qingmei Li",
            "Yang Zhang",
            "Peifeng Zhang",
            "Haohuan Fu",
            "Juepeng Zheng"
        ],
        "arxiv_id": "2512.02369",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Domain generalization for semantic segmentation aims to mitigate the degradation in model performance caused by domain shifts. However, in many real-world scenarios, we are unable to access the model parameters and architectural details due to privacy concerns and security constraints. Traditional fine-tuning or adaptation is hindered, leading to the demand for input-level strategies that can enhance generalization without modifying model weights. To this end, we propose a \\textbf{S}tyle-\\textbf{A}daptive \\textbf{GE}neralization framework (\\textbf{SAGE}), which improves the generalization of frozen models under privacy constraints. SAGE learns to synthesize visual prompts that implicitly align feature distributions across styles instead of directly fine-tuning the backbone. Specifically, we first utilize style transfer to construct a diverse style representation of the source domain, thereby learning a set of style characteristics that can cover a wide range of visual features. Then, the model adaptively fuses these style cues according to the visual context of each input, forming a dynamic prompt that harmonizes the image appearance without touching the interior of the model. Through this closed-loop design, SAGE effectively bridges the gap between frozen model invariance and the diversity of unseen domains. Extensive experiments on five benchmark datasets demonstrate that SAGE achieves competitive or superior performance compared to state-of-the-art methods under privacy constraints and outperforms full fine-tuning baselines in all settings.",
        "abstract_summary_gcp": "This paper addresses the challenge of domain generalization for semantic segmentation, particularly when model parameters and architectural details are inaccessible due to privacy and security constraints. Traditional fine-tuning is impossible under these conditions, necessitating input-level strategies.\n\nThe authors propose the **Style-Adaptive GEneralization framework (SAGE)**, designed to improve the generalization of *frozen* models. Instead of modifying model weights, SAGE learns to synthesize dynamic visual prompts that implicitly align feature distributions across different styles.\n\nSAGE operates in two main steps:\n1.  **Diverse Style Representation:** It first utilizes style transfer to construct a broad representation of style characteristics from the source domain.\n2.  **Adaptive Prompt Synthesis:** It then adaptively fuses these learned style cues based on the visual context of each input, generating a dynamic prompt that harmonizes the image's appearance *before* it enters the frozen model.\n\nThis closed-loop, input-level approach effectively bridges the gap between a frozen model's fixed nature and the diversity of unseen domains. Extensive experiments on five benchmark datasets show that SAGE achieves competitive or superior performance against state-of-the-art methods under privacy constraints, and remarkably, even surpasses full fine-tuning baselines in all evaluated settings.",
        "url": "https://www.semanticscholar.org/paper/fa72855efee1288b49208eb9fed73a32578108af",
        "isOpenAccess": false
    },
    "2512.02342": {
        "title": "Safeguarded Stochastic Polyak Step Sizes for Non-smooth Optimization: Robust Performance Without Small (Sub)Gradients",
        "authors": [
            "Dimitris Oikonomou",
            "Nicolas Loizou"
        ],
        "arxiv_id": "2512.02342",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Mathematics",
            "Computer Science"
        ],
        "abstract": "The stochastic Polyak step size (SPS) has proven to be a promising choice for stochastic gradient descent (SGD), delivering competitive performance relative to state-of-the-art methods on smooth convex and non-convex optimization problems, including deep neural network training. However, extensions of this approach to non-smooth settings remain in their early stages, often relying on interpolation assumptions or requiring knowledge of the optimal solution. In this work, we propose a novel SPS variant, Safeguarded SPS (SPS$_{safe}$), for the stochastic subgradient method, and provide rigorous convergence guarantees for non-smooth convex optimization with no need for strong assumptions. We further incorporate momentum into the update rule, yielding equally tight theoretical results. Comprehensive experiments on convex benchmarks and deep neural networks corroborate our theory: the proposed step size accelerates convergence, reduces variance, and consistently outperforms existing adaptive baselines. Finally, in the context of deep neural network training, our method demonstrates robust performance by addressing the vanishing gradient problem.",
        "abstract_summary_gcp": "This paper addresses the limitations of the Stochastic Polyak Step Size (SPS) in non-smooth optimization. While SPS is effective for smooth problems and deep learning, its non-smooth extensions typically rely on strong assumptions or require knowledge of the optimal solution.\n\nThe authors propose **Safeguarded SPS (SPS$_{safe}$)**, a novel variant for the stochastic subgradient method. SPS$_{safe}$ offers rigorous convergence guarantees for non-smooth convex optimization without requiring strong assumptions. They further incorporate momentum into the update rule, maintaining equally tight theoretical results.\n\nExperimental evaluations on convex benchmarks and deep neural networks demonstrate that SPS$_{safe}$ accelerates convergence, reduces variance, and consistently outperforms existing adaptive baselines. Notably, in deep neural network training, the method also exhibits robust performance by effectively addressing the vanishing gradient problem.",
        "url": "https://www.semanticscholar.org/paper/2f2b92685f43952d0cf1eb7803d1ab3f273d8861",
        "isOpenAccess": false
    },
    "Hybrid CNN-transformer framework with dynamic feature fusion for enhanced passport background texture classification": {
        "title": "Hybrid CNN-transformer framework with dynamic feature fusion for enhanced passport background texture classification",
        "authors": [
            "Maoqin Tian",
            "Lin Tang",
            "Jiafeng Xu",
            "Yibo Zhang",
            "Yong Yang",
            "Lingpei Zeng",
            "Eryang Chen",
            "Yuanlun Xie"
        ],
        "arxiv_id": null,
        "venue": "The Visual Computer",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/82fe2e52bf7f40954165c0ff36c21f5028e5783d",
        "isOpenAccess": false
    },
    "From data to diagnosis: An innovative approach to epilepsy prediction with CGTNet incorporating spatio-temporal features": {
        "title": "From data to diagnosis: An innovative approach to epilepsy prediction with CGTNet incorporating spatio-temporal features",
        "authors": [
            "Dianli Wang",
            "Enping Li",
            "Yang Wang",
            "Zhiyang Liu",
            "Aixia Sun",
            "Wei Wei",
            "Xuning Zhang",
            "Cheng Peng",
            "Fengtao Wei"
        ],
        "arxiv_id": null,
        "venue": "PLoS ONE",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": [
            "Medicine"
        ],
        "abstract": "Epilepsy affects around 50 million people globally, causing significant burdens. While many methods predict seizures, current models struggle with handling spatiotemporal features and balancing accuracy with computational efficiency.This paper introduces a novel deep learning architecture called CGTNet, which is composed of a multi-scale convolutional network, gated recurrent units (GRUs), and Sparse Transformers. It is specifically designed for analyzing elec-troencephalogram (EEG) data to predict epileptic seizures. CGTNet enhances the ability to extract spatiotemporal features from EEG signals, demonstrating its exceptional performance in seizure prediction through rigorous evaluation on the renowned CHB-MIT and SWEC-ETHZ EEG datasets. The model achieved an accuracy of 98.89%, sensitivity of 98.52%, specificity of 98.53%, an AUROC value of 0.97, and an MCC value of 0.975 on these datasets. These results not only highlight the technical innovations of CGTNet but also validate the immense potential of deep learning in processing medical signals. Our research provides an effective new tool for early detection and continuous monitoring of epilepsy, laying the foundation for advancing healthcare with artificial intelligence technology.",
        "abstract_summary_gcp": "Epilepsy affects millions globally, and while existing seizure prediction methods struggle with handling complex spatiotemporal features in EEG data and balancing accuracy with computational efficiency, this paper introduces a novel deep learning architecture called CGTNet.\n\nDesigned for epileptic seizure prediction using EEG data, CGTNet integrates a multi-scale convolutional network, Gated Recurrent Units (GRUs), and Sparse Transformers to enhance spatiotemporal feature extraction. Evaluated on the renowned CHB-MIT and SWEC-ETHZ EEG datasets, CGTNet achieved exceptional performance with 98.89% accuracy, 98.52% sensitivity, 98.53% specificity, an AUROC of 0.97, and an MCC of 0.975.\n\nThese results highlight CGTNet's technical innovations and validate the immense potential of deep learning in medical signal processing, offering an effective new tool for early detection and continuous monitoring of epilepsy, thereby advancing AI-driven healthcare.",
        "url": "https://www.semanticscholar.org/paper/99dc84029a8c14790354ccb0d9a5bd24fd9873cf",
        "isOpenAccess": false
    },
    "2512.03272": {
        "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?",
        "authors": [
            "Zhiyuan He",
            "Dingmin Wang"
        ],
        "arxiv_id": "2512.03272",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models\"overthink\"by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs'performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.",
        "abstract_summary_gcp": "Large Reasoning Models (LRMs) often rely on lengthy Chains of Thought (CoTs) for complex tasks, but this can lead to substantial token overhead, \"overthinking,\" and even incorrect answers. A promising alternative is the symbolic-solver-integrated approach, where LLMs generate executable code for external symbolic solvers.\n\nThis paper investigates when the symbolic-solver-integrated method is more effective than conventional long-CoTs. Experimental results indicate that this approach is beneficial primarily for problems requiring **limited implicit reasoning but involving a large search space**. While advanced LLMs like GPT-4o excel at deductive problems with shallow reasoning, the symbolic-solver-integrated method significantly improves performance in **constraint satisfaction problems** that demand repeated backtracking. Remarkably, when provided with a declarative exemplar, even a smaller model like CodeLlama-13B leveraging this symbolic integration can outperform GPT-4o on difficult Zebra puzzles.",
        "url": "https://www.semanticscholar.org/paper/1fca0173ce9e9a14bf8712284b28dc0d06c96952",
        "isOpenAccess": false
    },
    "2512.03185": {
        "title": "Nonlinear diffusion limit of non-local interactions on a sphere",
        "authors": [
            "M. Peletier",
            "Anna Shalova"
        ],
        "arxiv_id": "2512.03185",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Mathematics",
            "Physics"
        ],
        "abstract": "We study an aggregation PDE with competing attractive and repulsive forces on a sphere of arbitrary dimension. In particular, we consider the limit of strongly localized repulsion with a constant attraction term. We prove convergence of solutions of such a system to solutions of the aggregation-diffusion equation with a porous-medium-type diffusion term. The proof combines variational techniques with elements of harmonic analysis on a sphere. In particular, we characterize the square root of the convolution operator in terms of the spherical harmonics, which allows us to overcome difficulties arising due to the convolution on a sphere being non-commutative. The study is motivated by the toy model of transformers introduced by Geshkovski et al. (2025); and we discuss the applicability of the results to this model.",
        "abstract_summary_gcp": "This paper investigates an aggregation PDE on a sphere of arbitrary dimension, featuring competing attractive and repulsive forces. The core finding is a proof of convergence for solutions of this system to solutions of an aggregation-diffusion equation with a porous-medium-type diffusion term. This convergence occurs in the limit where repulsion is strongly localized and attraction remains constant.\n\nThe proof employs a combination of variational techniques and harmonic analysis on the sphere. A significant technical contribution involves characterizing the square root of the convolution operator using spherical harmonics, which helps overcome difficulties arising from the non-commutative nature of convolution on a sphere. The study is motivated by a toy model of transformers and discusses the applicability of its results to this model.",
        "url": "https://www.semanticscholar.org/paper/0c891825cd9d4dd7c695565dab405a8a7b2200dd",
        "isOpenAccess": false
    },
    "Islands of Signal and Transcriptomic Sequencing: A Foundation Model for Mutation and Lineage Prediction based on DNA Methylation and RNA-seq": {
        "title": "Islands of Signal and Transcriptomic Sequencing: A Foundation Model for Mutation and Lineage Prediction based on DNA Methylation and RNA-seq",
        "authors": [
            "Alexandros Alexakos",
            "Aris Tsirigos"
        ],
        "arxiv_id": null,
        "venue": "bioRxiv",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Biology"
        ],
        "abstract": null,
        "abstract_summary_gcp": "[요약 없음]",
        "url": "https://www.semanticscholar.org/paper/409e569050a2deae6f7213b75c9c1e326135547a",
        "isOpenAccess": false
    },
    "MD&A disclosure and investment efficiency: evidence from Chinese listed firms": {
        "title": "MD&A disclosure and investment efficiency: evidence from Chinese listed firms",
        "authors": [
            "Hongye Jia",
            "Xing Huang",
            "Chenggang Li",
            "Wanyue Zhang"
        ],
        "arxiv_id": null,
        "venue": "International Journal of Accounting &amp; Information Management",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": "\n \n In the context of Chinese listed firms, this study aims to test the relationship between a firm’s Management Discussions and Analysis (MD&A) forward-looking tone with its subsequent investment efficiency.\n \n \n \n This study constructed a sentiment dictionary on the basis of the BosonNLP semantic sentiment dictionary, negative word dictionary and degree adverb dictionary.\n \n \n \n The main findings show that firms with more optimistic MD&A tone tend to present higher subsequent investment efficiencies. This study further finds that this positive link is stronger in firms that disclose higher text quality of MD&A, is non-state owned and has fewer common owners. This study also discovers that, compared to their rival firms, firms with more optimistic MD&A tone show higher investment efficiency. However, their investment efficiency is not affected by rival firms’ MD&A tone.\n \n \n \n First, the empirical results should be carefully interpreted as they can only infer association instead of causality between forward-looking MD&A tones and subsequent investment efficiencies. Second, previous studies have criticised the low power of dictionary-based tone measures (Li, 2010). Therefore, similar to other studies that apply natural language text analysis techniques, the selection of MD&A tone measures and their reliability may affect empirical results. Finally, in the depth in this paper, this study did not further examine the effect of managerial characteristics and corporate governance mechanisms on the relationship between forward-looking MD&A tones and subsequent investment efficiencies.\n \n \n \n Few studies have identified the relationship between firms’ forward-looking textual disclosures and their investment efficiency. The focus on MD&A tone provides an interesting yet underexplored perspective to the current literature.\n",
        "abstract_summary_gcp": "This study investigated the relationship between the forward-looking tone of Management Discussions and Analysis (MD&A) and subsequent investment efficiency among Chinese listed firms. Utilizing a custom-built sentiment dictionary, the research found that firms with a more optimistic MD&A tone tend to exhibit higher subsequent investment efficiencies. This positive association is more pronounced in firms with higher MD&A text quality, non-state ownership, and fewer common owners. Furthermore, such optimistic firms demonstrate superior investment efficiency compared to their rivals, while rival firms' MD&A tone does not impact a firm's own investment efficiency.\n\nThe study acknowledges several limitations: it establishes association rather than causality, relies on potentially limited dictionary-based tone measures, and does not delve into the influence of managerial characteristics or corporate governance. Despite these, the research offers a novel contribution by addressing an under-researched area concerning forward-looking textual disclosures and their impact on investment efficiency.",
        "url": "https://www.semanticscholar.org/paper/450b4980e57bccf5fedbca0642d2afb1db39d0e5",
        "isOpenAccess": false
    },
    "SeismoQuakeGNN: a hybrid framework for spatio-temporal earthquake prediction with transformer-enhanced models": {
        "title": "SeismoQuakeGNN: a hybrid framework for spatio-temporal earthquake prediction with transformer-enhanced models",
        "authors": [
            "Anny Leema",
            "Ponnuraman Balakrishnan",
            "Gladys Gnana Kiruba",
            "Ganesarathinam Rajarajan",
            "Stuti Goel",
            "Prisha Aggarwal"
        ],
        "arxiv_id": null,
        "venue": "Frontiers in Artificial Intelligence",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": "Accurate predictions of earthquakes are crucial for disaster preparedness and risk mitigation. Conventional machine learning models like Random Forest, SVR, and XGBoost are frequently used for seismic forecasting; however, capturing the intricate spatiotemporal relationships in earthquake data remains a challenge. To overcome this issue, we propose SeismoQuakeGNN, a novel Graph Neural Network (GNN) and Transformer-based hybrid framework that integrates spatial and temporal learning for improved seismic forecasting. Unlike existing GNN-based models, SeismoQuakeGNN introduces an optimized spatial encoding mechanism to dynamically learn seismic interdependencies, coupled with a Transformer-driven attention module to capture long-range temporal correlations. Furthermore, initial experiments with XGBoost demonstrated its limitations in learning earthquake patterns, reinforcing the need for deep spatial–temporal modeling. The new SeismoQuakeGNN method is capable of substantial and efficient data processing of relationships in both space and time, as well as providing superior transfer to different seismic areas, thereby qualifying as a dependable starting point to extensive earthquake forecasting and hazard evaluation.",
        "abstract_summary_gcp": "Conventional machine learning models struggle to capture the complex spatiotemporal relationships crucial for accurate earthquake prediction. To address this, a novel hybrid framework called **SeismoQuakeGNN** is proposed. This model combines a Graph Neural Network (GNN) with a Transformer, integrating spatial and temporal learning.\n\nSeismoQuakeGNN distinguishes itself by:\n1.  **Optimized Spatial Encoding:** Dynamically learns seismic interdependencies.\n2.  **Transformer-driven Attention Module:** Captures long-range temporal correlations.\n\nThis approach overcomes the limitations of traditional models (like XGBoost, which showed poor performance in initial tests) by efficiently processing spatiotemporal data and offering superior transferability to different seismic areas. SeismoQuakeGNN thus provides a dependable foundation for improved earthquake forecasting and hazard evaluation.",
        "url": "https://www.semanticscholar.org/paper/11801e8081b12edf0fa3ee66a7732426fa105fcd",
        "isOpenAccess": false
    },
    "MultCPM: a multi-omics cancer recurrence prediction model utilizing a multi-head attention mechanism": {
        "title": "MultCPM: a multi-omics cancer recurrence prediction model utilizing a multi-head attention mechanism",
        "authors": [
            "Xiaofei Liu",
            "Haiyan Cui",
            "Tengcheng Que",
            "Sujuan Zhao",
            "Shaohui Zhong",
            "Wenjian Liu",
            "Yanling Hu"
        ],
        "arxiv_id": null,
        "venue": "PeerJ Computer Science",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": "Deep learning-based approaches for integrating multi-omics data offer a novel perspective on cancer recurrence prediction. However, existing methods struggle to manage the complex relationships within multi-omics data and the intrinsic correlations between samples, leading to suboptimal prediction accuracy. To tackle these challenges, we propose a multi-omics cancer recurrence prediction model (MultCPM), which employs a multi-head attention mechanism to extract key information from biological pathways. Integrated with a hierarchical fusion module, the model performs layered integration of omics data to effectively capture their interdependence. Ultimately, the fused information is consolidated into a unified feature matrix, refining critical features and their relationships across omics. Results from 5-fold cross-validation, repeated five times on Breast Cancer (BRCA), Bladder Cancer (BLCA), and Liver Cancer (LIHC) datasets, demonstrate that the MultCPM model achieves superior prediction performance and robustness. Additionally, Deep SHapley Additive exPlanations (DeepSHAP) was utilized to analyze the model’s interpretability, revealing key genes closely associated with cancer recurrence, thus providing valuable insights for biological research and the development of cancer recurrence prediction algorithms.\n \n The code is publicly available at\n https://github.com/dowell2016/MultCPM\n .\n",
        "abstract_summary_gcp": "Existing deep learning methods for multi-omics cancer recurrence prediction struggle with complex data relationships and sample correlations, resulting in suboptimal accuracy. To address this, the authors propose **MultCPM**, a multi-omics cancer recurrence prediction model.\n\nMultCPM utilizes a **multi-head attention mechanism** to extract crucial information from biological pathways and a **hierarchical fusion module** for layered integration of omics data, effectively capturing interdependencies and consolidating features into a unified matrix.\n\nEvaluated using repeated 5-fold cross-validation on Breast Cancer (BRCA), Bladder Cancer (BLCA), and Liver Cancer (LIHC) datasets, MultCPM demonstrates **superior prediction performance and robustness**. Furthermore, DeepSHAP analysis provides interpretability by identifying **key genes associated with cancer recurrence**, offering valuable biological insights.\n\nThe model's code is publicly available.",
        "url": "https://www.semanticscholar.org/paper/8c1d8f1c8c31dfa9df07934891ff5f6411600b04",
        "isOpenAccess": false
    },
    "Parameter-efficient fine-tuning for low-resource text classification: a comparative study of LoRA, IA3, and ReFT": {
        "title": "Parameter-efficient fine-tuning for low-resource text classification: a comparative study of LoRA, IA3, and ReFT",
        "authors": [
            "Steve Nwaiwu"
        ],
        "arxiv_id": null,
        "venue": "Frontiers in Big Data",
        "year": 2025,
        "publicationTypes": [
            "JournalArticle",
            "Review"
        ],
        "citationCount": 0,
        "fieldsOfStudy": null,
        "abstract": "\n The successful application of large-scale transformer models in Natural Language Processing (NLP) is often hindered by the substantial computational cost and data requirements of full fine-tuning. This challenge is particularly acute in low-resource settings, where standard fine-tuning can lead to catastrophic overfitting and model collapse. To address this, Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a promising solution. However, a direct comparative analysis of their trade-offs under unified low-resource conditions is lacking. This study provides a rigorous empirical evaluation of three prominent PEFT methods: Low-Rank Adaptation (LoRA), Infused Adapter by Inhibiting and Amplifying Inner Activations (IA\n 3\n ), and a Representation Fine-Tuning (ReFT) strategy. Using a DistilBERT base model on low-resource versions of the AG News and Amazon Reviews datasets, the present work compares these methods against a full fine-tuning baseline across accuracy, F1 score, trainable parameters, and GPU memory usage. The findings reveal that while all PEFT methods dramatically outperform the baseline, LoRA consistently achieves the highest F1 scores (0.909 on Amazon Reviews). Critically, ReFT delivers nearly identical performance (~98% of LoRA's F1 score) while training only ~3% of the parameters, establishing it as the most efficient method. This research demonstrates that PEFT is not merely an efficiency optimization, but a necessary tool for robust generalization in data-scarce environments, providing practitioners with a clear guide to navigate the performance—efficiency trade-off. By unifying these evaluations under controlled conditions, this study advances beyond fragmented prior research and offers a systematic framework for selecting PEFT strategies.\n",
        "abstract_summary_gcp": "This study addresses the challenges of fine-tuning large transformer models in low-resource NLP settings, where high computational cost and data requirements often lead to overfitting. It performs a rigorous empirical evaluation of three Parameter-Efficient Fine-Tuning (PEFT) methods—LoRA, IA3, and ReFT—against a full fine-tuning baseline.\n\nUsing a DistilBERT model on low-resource AG News and Amazon Reviews datasets, the research compared these methods across accuracy, F1 score, trainable parameters, and GPU memory. The findings show that all PEFT methods dramatically outperform the full fine-tuning baseline. LoRA consistently achieved the highest F1 scores (e.g., 0.909 on Amazon Reviews). However, ReFT delivered nearly identical performance (around 98% of LoRA's F1 score) while training only about 3% of the parameters, making it the most parameter-efficient method.\n\nThe study concludes that PEFT is not just an efficiency optimization, but a necessary tool for robust generalization in data-scarce environments, offering practitioners a clear guide for selecting fine-tuning strategies.",
        "url": "https://www.semanticscholar.org/paper/93169e570bfb0a333019d39f6e0cd7997b7fd7d8",
        "isOpenAccess": false
    },
    "2512.01208": {
        "title": "Pay Attention Later: From Vector Space Diffusion to Linearithmic Spectral Phase-Locking",
        "authors": [
            "Alper Yildirim",
            ".Ibrahim Yucedaug"
        ],
        "arxiv_id": "2512.01208",
        "venue": "",
        "year": 2025,
        "publicationTypes": null,
        "citationCount": 0,
        "fieldsOfStudy": [
            "Computer Science"
        ],
        "abstract": "Standard Transformers suffer from a\"Semantic Alignment Tax\", a prohibitive optimization cost required to organize a chaotic initialization into a coherent geometric map via local gradient diffusion. We hypothesize that this reliance on diffusive learning creates\"Catastrophic Rigidity\", rendering models unable to adapt to novel concepts without destroying their pre-trained reasoning capabilities. To isolate this phenomenon, we introduce Iterative Semantic Map Refinement (ISMR), a diagnostic protocol revealing that alignment is a fixed geometric barrier that scaling cannot solve; a 20-layer model overcomes this barrier no faster than a 1-layer model. We introduce the Phase-Resonant Intelligent Spectral Model (PRISM). PRISM encodes semantic identity as resonant frequencies in the complex domain (C^d) and replaces quadratic self-attention with linearithmic O(N log N) Gated Harmonic Convolutions. We validate PRISM on the WMT14 translation task. While the Standard Transformer maintains a slight edge in general competence on static benchmarks (23.88 vs 21.40 BLEU), it fails the\"Plasticity-Stability\"stress test completely. When injected with novel concepts, the Transformer suffers Catastrophic Forgetting, degrading by -10.55 BLEU points while achieving only 60% acquisition. In contrast, PRISM demonstrates Lossless Plasticity, achieving 96% 5-shot acquisition with negligible degradation (-0.84 BLEU). These results suggest that harmonic representations effectively decouple memory from reasoning, offering a structural solution to the plasticity-stability dilemma in real-time knowledge adaptation.",
        "abstract_summary_gcp": "Standard Transformers suffer from a \"Semantic Alignment Tax,\" a high optimization cost to create coherent semantic maps from chaotic initialization, which leads to \"Catastrophic Rigidity\"—the inability to adapt to new concepts without destroying existing reasoning. The Iterative Semantic Map Refinement (ISMR) diagnostic protocol reveals this alignment issue is a fixed geometric barrier that scaling cannot overcome.\n\nTo address this, the paper introduces the Phase-Resonant Intelligent Spectral Model (PRISM), which encodes semantic identity as resonant frequencies in the complex domain and replaces quadratic self-attention with linearithmic O(N log N) Gated Harmonic Convolutions.\n\nEvaluated on the WMT14 translation task, PRISM, while slightly behind Standard Transformers in general competence (21.40 vs 23.88 BLEU), demonstrates superior \"Plasticity-Stability.\" When exposed to novel concepts, Standard Transformers exhibit \"Catastrophic Forgetting\" (degrading by -10.55 BLEU with only 60% acquisition). In contrast, PRISM achieves \"Lossless Plasticity,\" with 96% 5-shot acquisition and negligible degradation (-0.84 BLEU). This suggests harmonic representations in PRISM effectively decouple memory from reasoning, providing a structural solution to the plasticity-stability dilemma for real-time knowledge adaptation.",
        "url": "https://www.semanticscholar.org/paper/16b525dd1230521ec684add6e9d7d14546de7492",
        "isOpenAccess": false
    }
}