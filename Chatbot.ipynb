{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9067c063",
   "metadata": {},
   "source": [
    "##### 1단계: LangChain 설치 및 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41827a5",
   "metadata": {},
   "source": [
    "gcloud cli 인증\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff545727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c931d",
   "metadata": {},
   "source": [
    "##### 2단계: Groq Qwen2.5 32B 설치 및 설정 지침  -> 대신 GCP gemini로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6afcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "\n",
    "# Vertex AI Gemini 기반 LLM\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-2.5-flash\",   # 또는 \"gemini-2.5-pro\"\n",
    "    temperature=0.0,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832462b4",
   "metadata": {},
   "source": [
    "##### 3단계: NVIDIA bge-m3 설치 및 설정 -> 대신 vertex 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda38ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -qU langchain-nvidia-ai-endpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b304f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c157a31",
   "metadata": {},
   "source": [
    "##### 4단계: Milvus 설치 및 설정 -> 대신 faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22e832",
   "metadata": {},
   "source": [
    "##### 5단계: RAG 챗봇 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b54a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] FAISS 인덱스 'paper.faiss' 로드 중...\n",
      "[INFO] 원본 데이터 'paper.json' 및 맵 'paper_to_model.json' 로드 중...\n",
      "[INFO] LangChain Docstore 재구성 중...\n",
      "[INFO] LangChain FAISS VectorStore 생성 중...\n",
      "[INFO] FAISS 인덱스 수동 로드 및 재구성 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "\n",
    "import vertexai\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "FAISS_INDEX_PATH = \"paper.faiss\"\n",
    "DATA_JSON_PATH   = \"paper.json\"\n",
    "MAP_JSON_PATH    = \"paper_to_model.json\"\n",
    "\n",
    "vector_store = None  \n",
    "\n",
    "try:\n",
    "    # 1. FAISS 인덱스 로드\n",
    "    print(f\"[INFO] FAISS 인덱스 '{FAISS_INDEX_PATH}' 로드 중...\")\n",
    "    index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "\n",
    "    # 2. JSON 데이터 로드\n",
    "    print(f\"[INFO] 원본 데이터 '{DATA_JSON_PATH}' 및 맵 '{MAP_JSON_PATH}' 로드 중...\")\n",
    "    with open(DATA_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        paper_DATA = json.load(f)\n",
    "\n",
    "    with open(MAP_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        # 예: { \"0\": \"BERT\", \"1\": \"GPT-3\", ... }\n",
    "        index_to_model_map = json.load(f)\n",
    "\n",
    "    # 3. LangChain Docstore 재구성\n",
    "    print(\"[INFO] LangChain Docstore 재구성 중...\")\n",
    "    docstore_dict = {}\n",
    "    index_to_docstore_id = {}\n",
    "\n",
    "    for str_idx, model_name in index_to_model_map.items():\n",
    "        int_idx = int(str_idx)\n",
    "\n",
    "        # docstore ID (여기서는 모델명을 그대로 사용)\n",
    "        doc_id = model_name\n",
    "\n",
    "        info = paper_DATA[model_name]\n",
    "\n",
    "        # build_database.py와 동일한 형태라고 가정\n",
    "        text = f\"모델명: {model_name}. \" + \" \".join(\n",
    "            f\"{key}: {value}\" for key, value in info.items() if value is not None\n",
    "        )\n",
    "\n",
    "        metadata = {\"model_name\": model_name, **info}\n",
    "        doc = Document(page_content=text, metadata=metadata)\n",
    "\n",
    "        docstore_dict[doc_id] = doc\n",
    "        index_to_docstore_id[int_idx] = doc_id\n",
    "\n",
    "    docstore = InMemoryDocstore(docstore_dict)\n",
    "\n",
    "    # 4. LangChain FAISS VectorStore 생성\n",
    "    print(\"[INFO] LangChain FAISS VectorStore 생성 중...\")\n",
    "    vector_store = FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "    )\n",
    "\n",
    "    print(\"[INFO] FAISS 인덱스 수동 로드 및 재구성 완료\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"[오류] 필수 파일을 찾을 수 없습니다: {e}\")\n",
    "    print(\"paper.faiss, paper.json, paper_to_model.json 파일 경로를 확인하세요.\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"[오류] FAISS 로드 중 예외 발생: {e}\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6005447",
   "metadata": {},
   "source": [
    "프롬프트 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a83bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] RAG 프롬프트 정의 중...\n",
      "[INFO] 프롬프트 설정 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"[INFO] RAG 프롬프트 정의 중...\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 논문/모델 정보를 설명하는 어시스턴트입니다. \"\n",
    "            \"주어진 context(논문 메타데이터와 설명)에 근거해서만 답변하세요. \"\n",
    "            \"모르면 모른다고 말하세요.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"질문: {question}\\n\\n\"\n",
    "            \"다음은 검색된 논문/모델 정보입니다:\\n\"\n",
    "            \"{context}\\n\\n\"\n",
    "            \"이 정보를 바탕으로 한국어로 자세히 답변해 주세요.\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"[INFO] 프롬프트 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084a693",
   "metadata": {},
   "source": [
    "(2) RAG 한 번 호출하는 함수만 두기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7b6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# RAG 함수 정의\n",
    "# ===============================\n",
    "\n",
    "def rag_answer(question: str, k: int = 4):\n",
    "    \"\"\"FAISS에서 관련 문서를 검색하고, LLM으로 답변을 생성하는 단일 RAG 함수.\"\"\"\n",
    "    if vector_store is None:\n",
    "        raise RuntimeError(\"vector_store가 초기화되지 않았습니다. FAISS 로드 셀을 먼저 확인하세요.\")\n",
    "\n",
    "    print(f\"[RAG] 검색 질의: {question}\")\n",
    "    docs = vector_store.similarity_search(question, k=k)\n",
    "    print(f\"[RAG] 검색된 문서 수: {len(docs)}\")\n",
    "\n",
    "    # 검색된 문서 내용을 하나의 문자열로 합치기\n",
    "    context_text = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # 프롬프트 + LLM 호출\n",
    "    messages = prompt.invoke({\"question\": question, \"context\": context_text})\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content, docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2cc3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 논문 챗봇 (RAG: Simple Version) ---\n",
      "\n",
      "[You]: BERT 논문이 뭐야?\n",
      "[RAG] 검색 질의: BERT 논문이 뭐야?\n",
      "[RAG] 검색된 문서 수: 3\n",
      "\n",
      "[Bot]: 네, 제공된 정보에 따르면 BERT 논문은 다음과 같습니다:\n",
      "\n",
      "*   **모델명:** BERT\n",
      "*   **제목:** BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "*   **저자:** Jacob Devlin et al.\n",
      "*   **발표 연도:** 2018년\n",
      "*   **주요 태스크:** 언어 이해 (Language Understanding)\n",
      "*   **핵심 키워드:** Transformer, Pre-training, Bidirectional (트랜스포머, 사전 훈련, 양방향)\n",
      "\n",
      "**요약:** BERT는 양방향 트랜스포머(Bidirectional Transformers)를 사전 훈련(Pre-training)하여 다양한 자연어 처리 태스크에서 최고 성능(SOTA)을 달성한 모델입니다.\n",
      "\n",
      "--- 참고한 문서 ---\n",
      "[1] BERT: 모델명: BERT. title: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding author: Jacob Devlin ...\n",
      "[2] GPT-3: 모델명: GPT-3. title: Language Models are Few-Shot Learners author: Tom B. Brown et al. year: 2020 task: Language Generatio...\n",
      "[3] ResNet: 모델명: ResNet. title: Deep Residual Learning for Image Recognition author: Kaiming He et al. year: 2015 task: Image Recogn...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- 논문 챗봇 (RAG: Simple Version) ---\")\n",
    "test_question = \"BERT 논문이 뭐야?\"\n",
    "\n",
    "if vector_store is None:\n",
    "    print(\"[오류] 벡터 스토어 로딩에 실패하여 RAG를 실행할 수 없습니다. 위 셀의 에러 메시지를 먼저 확인하세요.\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\n[You]: {test_question}\")\n",
    "        answer, used_docs = rag_answer(test_question, k=4)\n",
    "\n",
    "        print(f\"\\n[Bot]: {answer}\")\n",
    "\n",
    "        print(\"\\n--- 참고한 문서 ---\")\n",
    "        for i, doc in enumerate(used_docs):\n",
    "            model_name = doc.metadata.get(\"model_name\", \"Unknown\")\n",
    "            preview = doc.page_content[:120].replace(\"\\n\", \" \")\n",
    "            print(f\"[{i+1}] {model_name}: {preview}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"[오류] RAG 실행 중 예외 발생: {e}\")\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46e79790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 논문 챗봇 (RAG: Simple Version) ---\n",
      "\n",
      "[You]: BERT 논문 작가가 누구야?\n",
      "[RAG] 검색 질의: BERT 논문 작가가 누구야?\n",
      "[RAG] 검색된 문서 수: 3\n",
      "\n",
      "[Bot]: BERT 논문의 작가는 **Jacob Devlin 외 다수**입니다.\n",
      "\n",
      "--- 참고한 문서 ---\n",
      "[1] BERT: 모델명: BERT. title: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding author: Jacob Devlin ...\n",
      "[2] GPT-3: 모델명: GPT-3. title: Language Models are Few-Shot Learners author: Tom B. Brown et al. year: 2020 task: Language Generatio...\n",
      "[3] ResNet: 모델명: ResNet. title: Deep Residual Learning for Image Recognition author: Kaiming He et al. year: 2015 task: Image Recogn...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- 논문 챗봇 (RAG: Simple Version) ---\")\n",
    "test_question = \"BERT 논문 작가가 누구야?\"\n",
    "\n",
    "if vector_store is None:\n",
    "    print(\"[오류] 벡터 스토어 로딩에 실패하여 RAG를 실행할 수 없습니다. 위 셀의 에러 메시지를 먼저 확인하세요.\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\n[You]: {test_question}\")\n",
    "        answer, used_docs = rag_answer(test_question, k=4)\n",
    "\n",
    "        print(f\"\\n[Bot]: {answer}\")\n",
    "\n",
    "        print(\"\\n--- 참고한 문서 ---\")\n",
    "        for i, doc in enumerate(used_docs):\n",
    "            model_name = doc.metadata.get(\"model_name\", \"Unknown\")\n",
    "            preview = doc.page_content[:120].replace(\"\\n\", \" \")\n",
    "            print(f\"[{i+1}] {model_name}: {preview}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"[오류] RAG 실행 중 예외 발생: {e}\")\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c781994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citebot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
